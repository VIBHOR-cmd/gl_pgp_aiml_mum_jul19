{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CV with CNN | Project 1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdtYeZ_---1n",
        "colab_type": "text"
      },
      "source": [
        "# CV with CNN | Project 1\n",
        "The case study is from a dataset from Kaggle. \n",
        "\n",
        "Link to the Kaggle project site:\n",
        "\n",
        "https://www.kaggle.com/c/plant-seedlings-classification\n",
        "\n",
        "The dataset has to be downloaded from the above Kaggle web site.\n",
        "\n",
        "Can you differentiate a weed from a crop seedling?\n",
        "\n",
        "The ability to do so effectively can mean better crop yields and better stewardship of the environment.\n",
        "\n",
        "The Aarhus University Signal Processing group, in collaboration with the University of Southern\n",
        "Denmark, has recently released a dataset containing images of approximately 960 unique plants\n",
        "belonging to 12 species at several growth stages.\n",
        "\n",
        "The points distribution for this case is as follows:\n",
        "1. Read the images and generate the train and test dataset (5 points)\n",
        "2. Divide the data set into Train and validation data sets\n",
        "3. Initialize & build the model (10 points)\n",
        "4. Optimize the model (8 points)\n",
        "5. Predict the accuracy for both train and validation data (7 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90XxQv4u_9yu",
        "colab_type": "text"
      },
      "source": [
        "# 1. Read the images and generate the train and test dataset\n",
        "# 2. Divide the data set into Train and validation data sets\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_iPpMe_5xrh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1d09354c-da96-4b39-ffe5-b7c6ccc911cb"
      },
      "source": [
        "#For ease of working with large Dataset, we have unzipped & uploaded it to Google Drive\n",
        "#So, first let's mount the drive\n",
        "\n",
        "#Importing drive module from google.colab library\n",
        "from google.colab import drive\n",
        "\n",
        "#Mount the drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7LyqsMgDCUP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        },
        "outputId": "7cbe1614-9e6b-4536-9c3b-7c8957eeeed3"
      },
      "source": [
        "#Importing tensorflow library\n",
        "import tensorflow as tf\n",
        "\n",
        "#ImageDataGenerator declaration with 20% data as validation (80% for training)\n",
        "train_img_generator= tf.keras.preprocessing.image.ImageDataGenerator(validation_split=0.2)\n",
        "\n",
        "#ImageDataGenerator declaration for Test dataset\n",
        "test_img_generator= tf.keras.preprocessing.image.ImageDataGenerator()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAVkQBSoGmW2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "76ef6daa-a2e6-4f28-c659-0eeca9de3e38"
      },
      "source": [
        "#Build training generator. \n",
        "train_generator = train_img_generator.flow_from_directory('drive/My Drive/plant-seedlings-classification/train',\n",
        "                                                    target_size=(64, 64),\n",
        "                                                    subset='training',\n",
        "                                                    batch_size=64)\n",
        "\n",
        "#Build validation generator\n",
        "val_generator = train_img_generator.flow_from_directory('drive/My Drive/plant-seedlings-classification/train',\n",
        "                                                   target_size=(64, 64),                                                   \n",
        "                                                   subset='validation',\n",
        "                                                   batch_size=64)\n",
        "\n",
        "#Build test generator\n",
        "test_generator = test_img_generator.flow_from_directory('drive/My Drive/plant-seedlings-classification',\n",
        "                                                   classes=['test'],\n",
        "                                                   target_size=(64, 64),                                                   \n",
        "                                                   batch_size=64)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 3803 images belonging to 12 classes.\n",
            "Found 947 images belonging to 12 classes.\n",
            "Found 794 images belonging to 1 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0NI56WOHd3V3",
        "colab_type": "text"
      },
      "source": [
        "# 3. Initialize & build the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AThDY1cuDKSj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "a7096c51-000d-43e2-aef1-648776652a11"
      },
      "source": [
        "#Clear any previous model from memory\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "#Initialize model\n",
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "#normalize data\n",
        "model.add(tf.keras.layers.BatchNormalization(input_shape=(64,64,3)))\n",
        "\n",
        "#Add Conv Layer\n",
        "model.add(tf.keras.layers.Conv2D(16, kernel_size=(5,5), activation='relu'))\n",
        "\n",
        "#normalize data\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "#Add Conv Layer\n",
        "model.add(tf.keras.layers.Conv2D(32, kernel_size=(5,5), activation='relu'))\n",
        "\n",
        "#normalize data\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "#Add Max Pool layer\n",
        "model.add(tf.keras.layers.MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "#Add Dense Layers after flattening the data\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
        "\n",
        "#Add Dropout\n",
        "model.add(tf.keras.layers.Dropout(0.25))\n",
        "\n",
        "#Add Output Layer\n",
        "model.add(tf.keras.layers.Dense(12, activation='softmax'))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QINIqQpjDtCB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Specify Loass and Optimizer\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kG5-CY-2FhBz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "outputId": "d50dc2e4-5862-4d0c-8639-1acdda34ae50"
      },
      "source": [
        "#Model Summary\n",
        "model.summary()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "batch_normalization (BatchNo (None, 64, 64, 3)         12        \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 60, 60, 16)        1216      \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 60, 60, 16)        64        \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 56, 56, 32)        12832     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 56, 56, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 28, 28, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               3211392   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 12)                1548      \n",
            "=================================================================\n",
            "Total params: 3,227,192\n",
            "Trainable params: 3,227,090\n",
            "Non-trainable params: 102\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vB2Fw2OUQ6af",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a7112827-371f-460e-e13d-0f8a479cda83"
      },
      "source": [
        "#Fitting the model with Training dataset & validating the same with validation dataset\n",
        "model.fit_generator(train_generator,\n",
        "                    epochs=20,\n",
        "                    steps_per_epoch= 3803//64,  #Number of training images//batch_size\n",
        "                    validation_data=val_generator,\n",
        "                    validation_steps = 947//64 #Number of validation images//batch_size\n",
        "                   )"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "58/59 [============================>.] - ETA: 0s - loss: 2.7510 - acc: 0.3020Epoch 1/20\n",
            "59/59 [==============================] - 56s 948ms/step - loss: 2.7314 - acc: 0.3057 - val_loss: 2.5180 - val_acc: 0.2634\n",
            "Epoch 2/20\n",
            "58/59 [============================>.] - ETA: 0s - loss: 1.4684 - acc: 0.5165Epoch 1/20\n",
            "59/59 [==============================] - 55s 939ms/step - loss: 1.4707 - acc: 0.5154 - val_loss: 21.6079 - val_acc: 0.1306\n",
            "Epoch 3/20\n",
            "58/59 [============================>.] - ETA: 0s - loss: 1.2081 - acc: 0.5997Epoch 1/20\n",
            "59/59 [==============================] - 55s 936ms/step - loss: 1.2126 - acc: 0.5988 - val_loss: 26.1571 - val_acc: 0.2221\n",
            "Epoch 4/20\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.9090 - acc: 0.6921Epoch 1/20\n",
            "59/59 [==============================] - 54s 923ms/step - loss: 0.9071 - acc: 0.6918 - val_loss: 13.3600 - val_acc: 0.3214\n",
            "Epoch 5/20\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.7483 - acc: 0.7499Epoch 1/20\n",
            "59/59 [==============================] - 54s 912ms/step - loss: 0.7461 - acc: 0.7507 - val_loss: 4.3008 - val_acc: 0.4933\n",
            "Epoch 6/20\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.6185 - acc: 0.7872Epoch 1/20\n",
            "59/59 [==============================] - 53s 897ms/step - loss: 0.6173 - acc: 0.7871 - val_loss: 1.9040 - val_acc: 0.6228\n",
            "Epoch 7/20\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.5567 - acc: 0.8079Epoch 1/20\n",
            "59/59 [==============================] - 53s 897ms/step - loss: 0.5549 - acc: 0.8082 - val_loss: 1.3960 - val_acc: 0.6853\n",
            "Epoch 8/20\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.4257 - acc: 0.8505Epoch 1/20\n",
            "59/59 [==============================] - 52s 889ms/step - loss: 0.4253 - acc: 0.8502 - val_loss: 1.3162 - val_acc: 0.7020\n",
            "Epoch 9/20\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.3585 - acc: 0.8769Epoch 1/20\n",
            "59/59 [==============================] - 52s 884ms/step - loss: 0.3558 - acc: 0.8782 - val_loss: 1.2235 - val_acc: 0.7288\n",
            "Epoch 10/20\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.3321 - acc: 0.8846Epoch 1/20\n",
            "59/59 [==============================] - 52s 879ms/step - loss: 0.3328 - acc: 0.8844 - val_loss: 1.4723 - val_acc: 0.6998\n",
            "Epoch 11/20\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.2907 - acc: 0.9029Epoch 1/20\n",
            "59/59 [==============================] - 51s 861ms/step - loss: 0.2875 - acc: 0.9040 - val_loss: 1.2413 - val_acc: 0.7243\n",
            "Epoch 12/20\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.2746 - acc: 0.9107Epoch 1/20\n",
            "59/59 [==============================] - 50s 854ms/step - loss: 0.2752 - acc: 0.9101 - val_loss: 1.2672 - val_acc: 0.7031\n",
            "Epoch 13/20\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.2405 - acc: 0.9200Epoch 1/20\n",
            "59/59 [==============================] - 51s 863ms/step - loss: 0.2421 - acc: 0.9190 - val_loss: 1.2218 - val_acc: 0.7299\n",
            "Epoch 14/20\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.1932 - acc: 0.9309Epoch 1/20\n",
            "59/59 [==============================] - 50s 844ms/step - loss: 0.1930 - acc: 0.9310 - val_loss: 1.2639 - val_acc: 0.7533\n",
            "Epoch 15/20\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.1850 - acc: 0.9340Epoch 1/20\n",
            "59/59 [==============================] - 50s 844ms/step - loss: 0.1839 - acc: 0.9343 - val_loss: 1.3421 - val_acc: 0.7467\n",
            "Epoch 16/20\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.1661 - acc: 0.9412Epoch 1/20\n",
            "59/59 [==============================] - 51s 859ms/step - loss: 0.1653 - acc: 0.9411 - val_loss: 1.2640 - val_acc: 0.7556\n",
            "Epoch 17/20\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.1608 - acc: 0.9439Epoch 1/20\n",
            "59/59 [==============================] - 50s 854ms/step - loss: 0.1598 - acc: 0.9444 - val_loss: 1.4589 - val_acc: 0.7422\n",
            "Epoch 18/20\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.1533 - acc: 0.9467Epoch 1/20\n",
            "59/59 [==============================] - 51s 861ms/step - loss: 0.1531 - acc: 0.9473 - val_loss: 1.3633 - val_acc: 0.7321\n",
            "Epoch 19/20\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.1781 - acc: 0.9397Epoch 1/20\n",
            "59/59 [==============================] - 50s 839ms/step - loss: 0.1767 - acc: 0.9401 - val_loss: 1.5041 - val_acc: 0.7377\n",
            "Epoch 20/20\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.1833 - acc: 0.9445Epoch 1/20\n",
            "59/59 [==============================] - 49s 838ms/step - loss: 0.1850 - acc: 0.9444 - val_loss: 1.5227 - val_acc: 0.7333\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fcd5632e2e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jqm3O96oeStu",
        "colab_type": "text"
      },
      "source": [
        "# 4. Optimize the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kF_hLsvkRLP3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#With the above model, we saw that the Model has started overfitting on the Training dataset\n",
        "#To avoid this, we will use Image augmentation so that model learns on augmented image each time which will ensure that it doesn't overfit\n",
        "\n",
        "#ImageDataGenerator declaration with Image augmentation that will help avoid over-fitting of Training dataset\n",
        "train_img_generator= tf.keras.preprocessing.image.ImageDataGenerator(rotation_range=20,\n",
        "                                                                     width_shift_range=0.2,\n",
        "                                                                     height_shift_range=0.2,\n",
        "                                                                     horizontal_flip=True,\n",
        "                                                                     validation_split=0.2\n",
        "                                                                    )"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67J_O_4NhRmk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "193d4a74-c675-4260-c621-4010a5e89b70"
      },
      "source": [
        "#Build training generator. \n",
        "train_generator = train_img_generator.flow_from_directory('drive/My Drive/plant-seedlings-classification/train',\n",
        "                                                    target_size=(64, 64),\n",
        "                                                    subset='training',\n",
        "                                                    batch_size=64)\n",
        "\n",
        "#Build validation generator\n",
        "val_generator = train_img_generator.flow_from_directory('drive/My Drive/plant-seedlings-classification/train',\n",
        "                                                   target_size=(64, 64),                                                   \n",
        "                                                   subset='validation',\n",
        "                                                   batch_size=64)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 3803 images belonging to 12 classes.\n",
            "Found 947 images belonging to 12 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbUlMdNmiI77",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "043afc4f-3b8a-423d-ae26-63ee997f62f0"
      },
      "source": [
        "#Reinitialising the model without saving the learnt weights so that it starts from scratch\n",
        "json_string = model.to_json()\n",
        "model = tf.keras.models.model_from_json(json_string)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zm1tuG8Qq9l3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Specify Loass and Optimizer\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSdgia_fmHpe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "19cdb4d8-421f-44a2-be4b-1cf965470e41"
      },
      "source": [
        "#Fitting the model on Augmented Training dataset\n",
        "model.fit_generator(train_generator,\n",
        "                    epochs=100,\n",
        "                    steps_per_epoch= 3803//64,  #Number of training images//batch_size\n",
        "                    validation_data=val_generator,\n",
        "                    validation_steps = 947//64 #Number of test images//batch_size\n",
        "                   )"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 2.9798 - acc: 0.2354Epoch 1/100\n",
            "59/59 [==============================] - 60s 1s/step - loss: 2.9677 - acc: 0.2364 - val_loss: 2.4792 - val_acc: 0.1116\n",
            "Epoch 2/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 2.0481 - acc: 0.3290Epoch 1/100\n",
            "59/59 [==============================] - 60s 1s/step - loss: 2.0447 - acc: 0.3300 - val_loss: 3.7391 - val_acc: 0.2667\n",
            "Epoch 3/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 1.8734 - acc: 0.3812Epoch 1/100\n",
            "59/59 [==============================] - 59s 1s/step - loss: 1.8672 - acc: 0.3825 - val_loss: 12.0739 - val_acc: 0.1752\n",
            "Epoch 4/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 1.7514 - acc: 0.4161Epoch 1/100\n",
            "59/59 [==============================] - 58s 986ms/step - loss: 1.7487 - acc: 0.4164 - val_loss: 5.3540 - val_acc: 0.2879\n",
            "Epoch 5/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 1.6237 - acc: 0.4440Epoch 1/100\n",
            "59/59 [==============================] - 58s 985ms/step - loss: 1.6220 - acc: 0.4447 - val_loss: 2.3023 - val_acc: 0.4587\n",
            "Epoch 6/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 1.5701 - acc: 0.4766Epoch 1/100\n",
            "59/59 [==============================] - 57s 964ms/step - loss: 1.5732 - acc: 0.4773 - val_loss: 1.5203 - val_acc: 0.5279\n",
            "Epoch 7/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 1.5357 - acc: 0.4642Epoch 1/100\n",
            "59/59 [==============================] - 57s 973ms/step - loss: 1.5361 - acc: 0.4643 - val_loss: 1.5157 - val_acc: 0.5413\n",
            "Epoch 8/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 1.4304 - acc: 0.5067Epoch 1/100\n",
            "59/59 [==============================] - 57s 968ms/step - loss: 1.4371 - acc: 0.5055 - val_loss: 1.2119 - val_acc: 0.5926\n",
            "Epoch 9/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 1.4064 - acc: 0.5091Epoch 1/100\n",
            "59/59 [==============================] - 56s 951ms/step - loss: 1.4021 - acc: 0.5111 - val_loss: 1.1608 - val_acc: 0.6116\n",
            "Epoch 10/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 1.2995 - acc: 0.5494Epoch 1/100\n",
            "59/59 [==============================] - 56s 944ms/step - loss: 1.2971 - acc: 0.5520 - val_loss: 1.1763 - val_acc: 0.6105\n",
            "Epoch 11/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 1.2816 - acc: 0.5622Epoch 1/100\n",
            "59/59 [==============================] - 55s 934ms/step - loss: 1.2812 - acc: 0.5627 - val_loss: 1.3955 - val_acc: 0.5871\n",
            "Epoch 12/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 1.2961 - acc: 0.5478Epoch 1/100\n",
            "59/59 [==============================] - 55s 928ms/step - loss: 1.2954 - acc: 0.5480 - val_loss: 1.0298 - val_acc: 0.6685\n",
            "Epoch 13/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 1.2299 - acc: 0.5779Epoch 1/100\n",
            "59/59 [==============================] - 54s 920ms/step - loss: 1.2244 - acc: 0.5789 - val_loss: 1.0863 - val_acc: 0.6429\n",
            "Epoch 14/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 1.2787 - acc: 0.5654Epoch 1/100\n",
            "59/59 [==============================] - 54s 921ms/step - loss: 1.2766 - acc: 0.5654 - val_loss: 1.1271 - val_acc: 0.6652\n",
            "Epoch 15/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 1.1883 - acc: 0.5951Epoch 1/100\n",
            "59/59 [==============================] - 54s 918ms/step - loss: 1.1854 - acc: 0.5961 - val_loss: 0.9780 - val_acc: 0.6574\n",
            "Epoch 16/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 1.1204 - acc: 0.6101Epoch 1/100\n",
            "59/59 [==============================] - 53s 904ms/step - loss: 1.1245 - acc: 0.6099 - val_loss: 0.9975 - val_acc: 0.6853\n",
            "Epoch 17/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 1.1511 - acc: 0.6105Epoch 1/100\n",
            "59/59 [==============================] - 56s 950ms/step - loss: 1.1521 - acc: 0.6099 - val_loss: 0.9858 - val_acc: 0.7042\n",
            "Epoch 18/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 1.0604 - acc: 0.6339Epoch 1/100\n",
            "59/59 [==============================] - 53s 896ms/step - loss: 1.0608 - acc: 0.6334 - val_loss: 0.9383 - val_acc: 0.6987\n",
            "Epoch 19/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 1.0540 - acc: 0.6397Epoch 1/100\n",
            "59/59 [==============================] - 53s 907ms/step - loss: 1.0537 - acc: 0.6387 - val_loss: 0.9395 - val_acc: 0.6975\n",
            "Epoch 20/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 1.0111 - acc: 0.6493Epoch 1/100\n",
            "59/59 [==============================] - 54s 915ms/step - loss: 1.0098 - acc: 0.6488 - val_loss: 0.9080 - val_acc: 0.6998\n",
            "Epoch 21/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.9707 - acc: 0.6653Epoch 1/100\n",
            "59/59 [==============================] - 54s 920ms/step - loss: 0.9672 - acc: 0.6652 - val_loss: 1.0313 - val_acc: 0.6942\n",
            "Epoch 22/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.9771 - acc: 0.6668Epoch 1/100\n",
            "59/59 [==============================] - 56s 942ms/step - loss: 0.9747 - acc: 0.6679 - val_loss: 0.8790 - val_acc: 0.7199\n",
            "Epoch 23/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.9320 - acc: 0.6831Epoch 1/100\n",
            "59/59 [==============================] - 53s 902ms/step - loss: 0.9306 - acc: 0.6837 - val_loss: 0.8771 - val_acc: 0.7109\n",
            "Epoch 24/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.9385 - acc: 0.6770Epoch 1/100\n",
            "59/59 [==============================] - 54s 907ms/step - loss: 0.9434 - acc: 0.6753 - val_loss: 0.8257 - val_acc: 0.7188\n",
            "Epoch 25/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.8978 - acc: 0.6827Epoch 1/100\n",
            "59/59 [==============================] - 54s 910ms/step - loss: 0.8987 - acc: 0.6828 - val_loss: 0.8126 - val_acc: 0.7545\n",
            "Epoch 26/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.8328 - acc: 0.7058Epoch 1/100\n",
            "59/59 [==============================] - 55s 927ms/step - loss: 0.8329 - acc: 0.7063 - val_loss: 0.7271 - val_acc: 0.7679\n",
            "Epoch 27/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.8504 - acc: 0.7067Epoch 1/100\n",
            "59/59 [==============================] - 54s 919ms/step - loss: 0.8544 - acc: 0.7071 - val_loss: 0.6862 - val_acc: 0.7891\n",
            "Epoch 28/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.8031 - acc: 0.7195Epoch 1/100\n",
            "59/59 [==============================] - 55s 926ms/step - loss: 0.8063 - acc: 0.7202 - val_loss: 0.8328 - val_acc: 0.7522\n",
            "Epoch 29/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.7802 - acc: 0.7312Epoch 1/100\n",
            "59/59 [==============================] - 54s 918ms/step - loss: 0.7794 - acc: 0.7318 - val_loss: 0.8892 - val_acc: 0.7500\n",
            "Epoch 30/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.8178 - acc: 0.7159Epoch 1/100\n",
            "59/59 [==============================] - 53s 896ms/step - loss: 0.8173 - acc: 0.7170 - val_loss: 0.7618 - val_acc: 0.7790\n",
            "Epoch 31/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.7588 - acc: 0.7382Epoch 1/100\n",
            "59/59 [==============================] - 54s 917ms/step - loss: 0.7620 - acc: 0.7376 - val_loss: 0.7420 - val_acc: 0.7801\n",
            "Epoch 32/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.7391 - acc: 0.7365Epoch 1/100\n",
            "59/59 [==============================] - 53s 904ms/step - loss: 0.7404 - acc: 0.7354 - val_loss: 0.6486 - val_acc: 0.8125\n",
            "Epoch 33/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.7351 - acc: 0.7396Epoch 1/100\n",
            "59/59 [==============================] - 55s 930ms/step - loss: 0.7383 - acc: 0.7382 - val_loss: 0.7049 - val_acc: 0.7835\n",
            "Epoch 34/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.7912 - acc: 0.7355Epoch 1/100\n",
            "59/59 [==============================] - 53s 901ms/step - loss: 0.7905 - acc: 0.7366 - val_loss: 0.6802 - val_acc: 0.8025\n",
            "Epoch 35/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.7347 - acc: 0.7548Epoch 1/100\n",
            "59/59 [==============================] - 55s 924ms/step - loss: 0.7337 - acc: 0.7553 - val_loss: 0.8078 - val_acc: 0.7533\n",
            "Epoch 36/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.6800 - acc: 0.7653Epoch 1/100\n",
            "59/59 [==============================] - 54s 911ms/step - loss: 0.6845 - acc: 0.7642 - val_loss: 0.6322 - val_acc: 0.8348\n",
            "Epoch 37/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.6566 - acc: 0.7632Epoch 1/100\n",
            "59/59 [==============================] - 54s 918ms/step - loss: 0.6511 - acc: 0.7656 - val_loss: 0.7250 - val_acc: 0.7824\n",
            "Epoch 38/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.6916 - acc: 0.7598Epoch 1/100\n",
            "59/59 [==============================] - 52s 880ms/step - loss: 0.6897 - acc: 0.7604 - val_loss: 0.7204 - val_acc: 0.8125\n",
            "Epoch 39/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.6477 - acc: 0.7744Epoch 1/100\n",
            "59/59 [==============================] - 54s 911ms/step - loss: 0.6476 - acc: 0.7740 - val_loss: 0.6618 - val_acc: 0.8013\n",
            "Epoch 40/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.6693 - acc: 0.7629Epoch 1/100\n",
            "59/59 [==============================] - 55s 934ms/step - loss: 0.6703 - acc: 0.7622 - val_loss: 0.6826 - val_acc: 0.8036\n",
            "Epoch 41/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.6346 - acc: 0.7799Epoch 1/100\n",
            "59/59 [==============================] - 54s 907ms/step - loss: 0.6333 - acc: 0.7802 - val_loss: 0.6473 - val_acc: 0.8214\n",
            "Epoch 42/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.6232 - acc: 0.7780Epoch 1/100\n",
            "59/59 [==============================] - 52s 879ms/step - loss: 0.6211 - acc: 0.7786 - val_loss: 0.5748 - val_acc: 0.8371\n",
            "Epoch 43/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.6295 - acc: 0.7856Epoch 1/100\n",
            "59/59 [==============================] - 54s 915ms/step - loss: 0.6349 - acc: 0.7826 - val_loss: 0.6125 - val_acc: 0.8270\n",
            "Epoch 44/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.6184 - acc: 0.7848Epoch 1/100\n",
            "59/59 [==============================] - 55s 925ms/step - loss: 0.6203 - acc: 0.7850 - val_loss: 0.5789 - val_acc: 0.8147\n",
            "Epoch 45/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.5694 - acc: 0.7970Epoch 1/100\n",
            "59/59 [==============================] - 53s 901ms/step - loss: 0.5693 - acc: 0.7973 - val_loss: 0.6427 - val_acc: 0.8281\n",
            "Epoch 46/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.5794 - acc: 0.7938Epoch 1/100\n",
            "59/59 [==============================] - 52s 877ms/step - loss: 0.5790 - acc: 0.7939 - val_loss: 0.7184 - val_acc: 0.8036\n",
            "Epoch 47/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.6382 - acc: 0.7777Epoch 1/100\n",
            "59/59 [==============================] - 55s 940ms/step - loss: 0.6395 - acc: 0.7762 - val_loss: 0.7315 - val_acc: 0.7746\n",
            "Epoch 48/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.5603 - acc: 0.7956Epoch 1/100\n",
            "59/59 [==============================] - 54s 917ms/step - loss: 0.5583 - acc: 0.7962 - val_loss: 0.5683 - val_acc: 0.8504\n",
            "Epoch 49/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.5686 - acc: 0.8008Epoch 1/100\n",
            "59/59 [==============================] - 53s 900ms/step - loss: 0.5679 - acc: 0.8018 - val_loss: 0.5621 - val_acc: 0.8504\n",
            "Epoch 50/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.5745 - acc: 0.8022Epoch 1/100\n",
            "59/59 [==============================] - 53s 896ms/step - loss: 0.5753 - acc: 0.8016 - val_loss: 0.6918 - val_acc: 0.8192\n",
            "Epoch 51/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.5682 - acc: 0.8033Epoch 1/100\n",
            "59/59 [==============================] - 54s 924ms/step - loss: 0.5667 - acc: 0.8040 - val_loss: 0.5981 - val_acc: 0.8237\n",
            "Epoch 52/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.5314 - acc: 0.8144Epoch 1/100\n",
            "59/59 [==============================] - 53s 895ms/step - loss: 0.5308 - acc: 0.8141 - val_loss: 0.6579 - val_acc: 0.8114\n",
            "Epoch 53/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.5136 - acc: 0.8152Epoch 1/100\n",
            "59/59 [==============================] - 54s 908ms/step - loss: 0.5128 - acc: 0.8149 - val_loss: 0.5555 - val_acc: 0.8292\n",
            "Epoch 54/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.5406 - acc: 0.8147Epoch 1/100\n",
            "59/59 [==============================] - 53s 906ms/step - loss: 0.5426 - acc: 0.8144 - val_loss: 0.5023 - val_acc: 0.8549\n",
            "Epoch 55/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.5223 - acc: 0.8112Epoch 1/100\n",
            "59/59 [==============================] - 53s 902ms/step - loss: 0.5237 - acc: 0.8098 - val_loss: 0.6179 - val_acc: 0.8125\n",
            "Epoch 56/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.5378 - acc: 0.8122Epoch 1/100\n",
            "59/59 [==============================] - 54s 919ms/step - loss: 0.5386 - acc: 0.8112 - val_loss: 0.7288 - val_acc: 0.8114\n",
            "Epoch 57/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.5353 - acc: 0.8090Epoch 1/100\n",
            "59/59 [==============================] - 53s 893ms/step - loss: 0.5309 - acc: 0.8098 - val_loss: 0.5194 - val_acc: 0.8460\n",
            "Epoch 58/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.5269 - acc: 0.8095Epoch 1/100\n",
            "59/59 [==============================] - 54s 909ms/step - loss: 0.5238 - acc: 0.8106 - val_loss: 0.7082 - val_acc: 0.8170\n",
            "Epoch 59/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.4937 - acc: 0.8264Epoch 1/100\n",
            "59/59 [==============================] - 53s 903ms/step - loss: 0.4947 - acc: 0.8256 - val_loss: 0.7538 - val_acc: 0.7824\n",
            "Epoch 60/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.5045 - acc: 0.8245Epoch 1/100\n",
            "59/59 [==============================] - 53s 897ms/step - loss: 0.5075 - acc: 0.8229 - val_loss: 0.5364 - val_acc: 0.8527\n",
            "Epoch 61/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.4860 - acc: 0.8272Epoch 1/100\n",
            "59/59 [==============================] - 50s 856ms/step - loss: 0.4829 - acc: 0.8275 - val_loss: 0.6630 - val_acc: 0.8449\n",
            "Epoch 62/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.5294 - acc: 0.8248Epoch 1/100\n",
            "59/59 [==============================] - 58s 985ms/step - loss: 0.5296 - acc: 0.8240 - val_loss: 0.5540 - val_acc: 0.8549\n",
            "Epoch 63/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.4733 - acc: 0.8241Epoch 1/100\n",
            "59/59 [==============================] - 58s 977ms/step - loss: 0.4727 - acc: 0.8244 - val_loss: 0.6888 - val_acc: 0.8103\n",
            "Epoch 64/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.4891 - acc: 0.8290Epoch 1/100\n",
            "59/59 [==============================] - 57s 966ms/step - loss: 0.4907 - acc: 0.8282 - val_loss: 0.6551 - val_acc: 0.8292\n",
            "Epoch 65/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.4917 - acc: 0.8211Epoch 1/100\n",
            "59/59 [==============================] - 57s 964ms/step - loss: 0.4894 - acc: 0.8216 - val_loss: 0.4961 - val_acc: 0.8538\n",
            "Epoch 66/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.4977 - acc: 0.8201Epoch 1/100\n",
            "59/59 [==============================] - 57s 960ms/step - loss: 0.4937 - acc: 0.8221 - val_loss: 0.6259 - val_acc: 0.8538\n",
            "Epoch 67/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.4570 - acc: 0.8392Epoch 1/100\n",
            "59/59 [==============================] - 56s 946ms/step - loss: 0.4592 - acc: 0.8379 - val_loss: 0.5877 - val_acc: 0.8449\n",
            "Epoch 68/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.4958 - acc: 0.8253Epoch 1/100\n",
            "59/59 [==============================] - 56s 941ms/step - loss: 0.4964 - acc: 0.8251 - val_loss: 0.5369 - val_acc: 0.8326\n",
            "Epoch 69/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.4700 - acc: 0.8307Epoch 1/100\n",
            "59/59 [==============================] - 55s 934ms/step - loss: 0.4703 - acc: 0.8302 - val_loss: 0.5972 - val_acc: 0.8438\n",
            "Epoch 70/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.4372 - acc: 0.8460Epoch 1/100\n",
            "59/59 [==============================] - 55s 926ms/step - loss: 0.4370 - acc: 0.8459 - val_loss: 0.5527 - val_acc: 0.8605\n",
            "Epoch 71/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.4491 - acc: 0.8517Epoch 1/100\n",
            "59/59 [==============================] - 54s 916ms/step - loss: 0.4476 - acc: 0.8518 - val_loss: 0.4779 - val_acc: 0.8627\n",
            "Epoch 72/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.5037 - acc: 0.8294Epoch 1/100\n",
            "59/59 [==============================] - 53s 903ms/step - loss: 0.4988 - acc: 0.8310 - val_loss: 0.5425 - val_acc: 0.8672\n",
            "Epoch 73/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.4034 - acc: 0.8556Epoch 1/100\n",
            "59/59 [==============================] - 54s 923ms/step - loss: 0.4033 - acc: 0.8557 - val_loss: 0.5637 - val_acc: 0.8583\n",
            "Epoch 74/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.4667 - acc: 0.8370Epoch 1/100\n",
            "59/59 [==============================] - 53s 902ms/step - loss: 0.4665 - acc: 0.8371 - val_loss: 0.4788 - val_acc: 0.8650\n",
            "Epoch 75/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.4167 - acc: 0.8473Epoch 1/100\n",
            "59/59 [==============================] - 54s 912ms/step - loss: 0.4193 - acc: 0.8459 - val_loss: 0.5515 - val_acc: 0.8449\n",
            "Epoch 76/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.4389 - acc: 0.8408Epoch 1/100\n",
            "59/59 [==============================] - 53s 902ms/step - loss: 0.4381 - acc: 0.8422 - val_loss: 0.5995 - val_acc: 0.8426\n",
            "Epoch 77/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.4144 - acc: 0.8531Epoch 1/100\n",
            "59/59 [==============================] - 53s 902ms/step - loss: 0.4147 - acc: 0.8529 - val_loss: 0.5929 - val_acc: 0.8560\n",
            "Epoch 78/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.4099 - acc: 0.8601Epoch 1/100\n",
            "59/59 [==============================] - 53s 902ms/step - loss: 0.4082 - acc: 0.8601 - val_loss: 0.5898 - val_acc: 0.8583\n",
            "Epoch 79/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.4587 - acc: 0.8346Epoch 1/100\n",
            "59/59 [==============================] - 55s 939ms/step - loss: 0.4556 - acc: 0.8353 - val_loss: 0.5248 - val_acc: 0.8538\n",
            "Epoch 80/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.4332 - acc: 0.8482Epoch 1/100\n",
            "59/59 [==============================] - 53s 900ms/step - loss: 0.4341 - acc: 0.8468 - val_loss: 0.4501 - val_acc: 0.8828\n",
            "Epoch 81/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.4147 - acc: 0.8604Epoch 1/100\n",
            "59/59 [==============================] - 54s 908ms/step - loss: 0.4134 - acc: 0.8604 - val_loss: 0.4531 - val_acc: 0.8817\n",
            "Epoch 82/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.4189 - acc: 0.8612Epoch 1/100\n",
            "59/59 [==============================] - 52s 883ms/step - loss: 0.4178 - acc: 0.8612 - val_loss: 0.5259 - val_acc: 0.8583\n",
            "Epoch 83/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.4595 - acc: 0.8438Epoch 1/100\n",
            "59/59 [==============================] - 53s 906ms/step - loss: 0.4588 - acc: 0.8435 - val_loss: 0.5019 - val_acc: 0.8672\n",
            "Epoch 84/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.4245 - acc: 0.8503Epoch 1/100\n",
            "59/59 [==============================] - 53s 903ms/step - loss: 0.4242 - acc: 0.8513 - val_loss: 0.5077 - val_acc: 0.8527\n",
            "Epoch 85/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.4184 - acc: 0.8503Epoch 1/100\n",
            "59/59 [==============================] - 53s 903ms/step - loss: 0.4169 - acc: 0.8516 - val_loss: 0.5425 - val_acc: 0.8739\n",
            "Epoch 86/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.3866 - acc: 0.8640Epoch 1/100\n",
            "59/59 [==============================] - 53s 904ms/step - loss: 0.3856 - acc: 0.8641 - val_loss: 0.6612 - val_acc: 0.8549\n",
            "Epoch 87/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.4399 - acc: 0.8452Epoch 1/100\n",
            "59/59 [==============================] - 54s 911ms/step - loss: 0.4371 - acc: 0.8459 - val_loss: 0.4954 - val_acc: 0.8906\n",
            "Epoch 88/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.3898 - acc: 0.8543Epoch 1/100\n",
            "59/59 [==============================] - 52s 878ms/step - loss: 0.3894 - acc: 0.8544 - val_loss: 0.4575 - val_acc: 0.8884\n",
            "Epoch 89/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.3960 - acc: 0.8574Epoch 1/100\n",
            "59/59 [==============================] - 52s 884ms/step - loss: 0.3982 - acc: 0.8569 - val_loss: 0.6964 - val_acc: 0.8237\n",
            "Epoch 90/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.4187 - acc: 0.8556Epoch 1/100\n",
            "59/59 [==============================] - 54s 918ms/step - loss: 0.4171 - acc: 0.8559 - val_loss: 0.5496 - val_acc: 0.8627\n",
            "Epoch 91/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.3822 - acc: 0.8628Epoch 1/100\n",
            "59/59 [==============================] - 53s 906ms/step - loss: 0.3801 - acc: 0.8641 - val_loss: 0.5891 - val_acc: 0.8795\n",
            "Epoch 92/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.4165 - acc: 0.8484Epoch 1/100\n",
            "59/59 [==============================] - 53s 892ms/step - loss: 0.4140 - acc: 0.8497 - val_loss: 0.5629 - val_acc: 0.8616\n",
            "Epoch 93/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.4169 - acc: 0.8599Epoch 1/100\n",
            "59/59 [==============================] - 52s 889ms/step - loss: 0.4185 - acc: 0.8583 - val_loss: 0.6068 - val_acc: 0.8504\n",
            "Epoch 94/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.3913 - acc: 0.8602Epoch 1/100\n",
            "59/59 [==============================] - 52s 887ms/step - loss: 0.3903 - acc: 0.8610 - val_loss: 0.6439 - val_acc: 0.8549\n",
            "Epoch 95/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.3472 - acc: 0.8736Epoch 1/100\n",
            "59/59 [==============================] - 54s 918ms/step - loss: 0.3530 - acc: 0.8722 - val_loss: 0.5995 - val_acc: 0.8661\n",
            "Epoch 96/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.3782 - acc: 0.8639Epoch 1/100\n",
            "59/59 [==============================] - 53s 890ms/step - loss: 0.3790 - acc: 0.8636 - val_loss: 0.4821 - val_acc: 0.8783\n",
            "Epoch 97/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.3655 - acc: 0.8653Epoch 1/100\n",
            "59/59 [==============================] - 54s 907ms/step - loss: 0.3658 - acc: 0.8649 - val_loss: 0.5232 - val_acc: 0.8705\n",
            "Epoch 98/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.3629 - acc: 0.8675Epoch 1/100\n",
            "59/59 [==============================] - 54s 909ms/step - loss: 0.3598 - acc: 0.8687 - val_loss: 0.6664 - val_acc: 0.8616\n",
            "Epoch 99/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.3704 - acc: 0.8686Epoch 1/100\n",
            "59/59 [==============================] - 53s 900ms/step - loss: 0.3675 - acc: 0.8687 - val_loss: 0.5313 - val_acc: 0.8605\n",
            "Epoch 100/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.3817 - acc: 0.8615Epoch 1/100\n",
            "59/59 [==============================] - 54s 912ms/step - loss: 0.3864 - acc: 0.8607 - val_loss: 0.6272 - val_acc: 0.8594\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fcc808451d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XP9ZiBeWq1pp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#The above model got rid of over-fitting as most of the times validation accuracy was better than training accuracy\n",
        "#But, as we can see the accuracy for both training dataset & validation dataset has started saturating between 85% and 90%\n",
        "#Let's try to add couple of more CNN layers & see how the model performs\n",
        "\n",
        "#Clear any previous model from memory\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "#Initialize model\n",
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "#normalize data\n",
        "model.add(tf.keras.layers.BatchNormalization(input_shape=(64,64,3)))\n",
        "\n",
        "#Add Conv Layer\n",
        "model.add(tf.keras.layers.Conv2D(16, kernel_size=(5,5), activation='relu'))\n",
        "\n",
        "#normalize data\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "#Add Conv Layer\n",
        "model.add(tf.keras.layers.Conv2D(32, kernel_size=(5,5), activation='relu'))\n",
        "\n",
        "#normalize data\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "#Add Conv Layer\n",
        "model.add(tf.keras.layers.Conv2D(32, kernel_size=(3,3), activation='relu'))\n",
        "\n",
        "#normalize data\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "#Add Conv Layer\n",
        "model.add(tf.keras.layers.Conv2D(16, kernel_size=(3,3), activation='relu'))\n",
        "\n",
        "#normalize data\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "#Add Max Pool layer\n",
        "model.add(tf.keras.layers.MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "#Add Dense Layers after flattening the data\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
        "\n",
        "#Add Dropout\n",
        "model.add(tf.keras.layers.Dropout(0.25))\n",
        "\n",
        "#Add Output Layer\n",
        "model.add(tf.keras.layers.Dense(12, activation='softmax'))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Kwx1WGmAs6V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Specify Loass and Optimizer\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jB7FMXftBAZ4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        },
        "outputId": "9ccbc2ac-041a-4d11-da21-2af5e8af90dd"
      },
      "source": [
        "#Model Summary\n",
        "model.summary()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "batch_normalization (BatchNo (None, 64, 64, 3)         12        \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 60, 60, 16)        1216      \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 60, 60, 16)        64        \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 56, 56, 32)        12832     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 56, 56, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 54, 54, 32)        9248      \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 54, 54, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 52, 52, 16)        4624      \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 52, 52, 16)        64        \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 26, 26, 16)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 10816)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               1384576   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 12)                1548      \n",
            "=================================================================\n",
            "Total params: 1,414,440\n",
            "Trainable params: 1,414,242\n",
            "Non-trainable params: 198\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aubHjCJIBF2g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fd4f48f5-4271-4c8c-d312-4766f8a290fa"
      },
      "source": [
        "#Fitting the model with Training dataset & validating the same with validation dataset\n",
        "model.fit_generator(train_generator,\n",
        "                    epochs=100,\n",
        "                    steps_per_epoch= 3803//64,  #Number of training images//batch_size\n",
        "                    validation_data=val_generator,\n",
        "                    validation_steps = 947//64 #Number of validation images//batch_size\n",
        "                   )"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 2.4263 - acc: 0.2884Epoch 1/100\n",
            "59/59 [==============================] - 60s 1s/step - loss: 2.4176 - acc: 0.2894 - val_loss: 7.2331 - val_acc: 0.1395\n",
            "Epoch 2/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 1.7476 - acc: 0.4220Epoch 1/100\n",
            "59/59 [==============================] - 60s 1s/step - loss: 1.7492 - acc: 0.4226 - val_loss: 3.0907 - val_acc: 0.2422\n",
            "Epoch 3/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 1.5660 - acc: 0.4784Epoch 1/100\n",
            "59/59 [==============================] - 59s 1s/step - loss: 1.5640 - acc: 0.4790 - val_loss: 2.5913 - val_acc: 0.3516\n",
            "Epoch 4/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 1.4614 - acc: 0.5208Epoch 1/100\n",
            "59/59 [==============================] - 59s 1s/step - loss: 1.4602 - acc: 0.5205 - val_loss: 2.4663 - val_acc: 0.4029\n",
            "Epoch 5/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 1.3443 - acc: 0.5388Epoch 1/100\n",
            "59/59 [==============================] - 58s 987ms/step - loss: 1.3422 - acc: 0.5389 - val_loss: 1.2670 - val_acc: 0.5748\n",
            "Epoch 6/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 1.2425 - acc: 0.5829Epoch 1/100\n",
            "59/59 [==============================] - 58s 987ms/step - loss: 1.2424 - acc: 0.5841 - val_loss: 1.1850 - val_acc: 0.6239\n",
            "Epoch 7/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 1.1227 - acc: 0.6237Epoch 1/100\n",
            "59/59 [==============================] - 58s 979ms/step - loss: 1.1244 - acc: 0.6245 - val_loss: 1.1241 - val_acc: 0.6417\n",
            "Epoch 8/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 1.1020 - acc: 0.6272Epoch 1/100\n",
            "59/59 [==============================] - 57s 968ms/step - loss: 1.0983 - acc: 0.6272 - val_loss: 1.3774 - val_acc: 0.5859\n",
            "Epoch 9/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 1.0481 - acc: 0.6462Epoch 1/100\n",
            "59/59 [==============================] - 57s 966ms/step - loss: 1.0469 - acc: 0.6464 - val_loss: 1.2145 - val_acc: 0.6339\n",
            "Epoch 10/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.9885 - acc: 0.6626Epoch 1/100\n",
            "59/59 [==============================] - 57s 960ms/step - loss: 0.9879 - acc: 0.6625 - val_loss: 0.9895 - val_acc: 0.6775\n",
            "Epoch 11/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.9386 - acc: 0.6686Epoch 1/100\n",
            "59/59 [==============================] - 55s 939ms/step - loss: 0.9350 - acc: 0.6705 - val_loss: 0.9924 - val_acc: 0.6908\n",
            "Epoch 12/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.9021 - acc: 0.6920Epoch 1/100\n",
            "59/59 [==============================] - 54s 920ms/step - loss: 0.9015 - acc: 0.6922 - val_loss: 0.8566 - val_acc: 0.7254\n",
            "Epoch 13/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.8530 - acc: 0.7154Epoch 1/100\n",
            "59/59 [==============================] - 54s 919ms/step - loss: 0.8481 - acc: 0.7162 - val_loss: 1.1121 - val_acc: 0.6786\n",
            "Epoch 14/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.8233 - acc: 0.7085Epoch 1/100\n",
            "59/59 [==============================] - 55s 936ms/step - loss: 0.8253 - acc: 0.7095 - val_loss: 0.7690 - val_acc: 0.7634\n",
            "Epoch 15/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.8140 - acc: 0.7221Epoch 1/100\n",
            "59/59 [==============================] - 54s 922ms/step - loss: 0.8113 - acc: 0.7231 - val_loss: 0.8705 - val_acc: 0.7455\n",
            "Epoch 16/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.8191 - acc: 0.7279Epoch 1/100\n",
            "59/59 [==============================] - 56s 948ms/step - loss: 0.8155 - acc: 0.7277 - val_loss: 0.7171 - val_acc: 0.7667\n",
            "Epoch 17/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.6992 - acc: 0.7551Epoch 1/100\n",
            "59/59 [==============================] - 55s 926ms/step - loss: 0.6989 - acc: 0.7542 - val_loss: 0.7717 - val_acc: 0.7578\n",
            "Epoch 18/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.7227 - acc: 0.7433Epoch 1/100\n",
            "59/59 [==============================] - 54s 920ms/step - loss: 0.7188 - acc: 0.7453 - val_loss: 0.7549 - val_acc: 0.7857\n",
            "Epoch 19/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.7061 - acc: 0.7532Epoch 1/100\n",
            "59/59 [==============================] - 55s 929ms/step - loss: 0.7019 - acc: 0.7550 - val_loss: 0.6882 - val_acc: 0.7913\n",
            "Epoch 20/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.6682 - acc: 0.7610Epoch 1/100\n",
            "59/59 [==============================] - 54s 922ms/step - loss: 0.6667 - acc: 0.7619 - val_loss: 0.7287 - val_acc: 0.7891\n",
            "Epoch 21/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.6862 - acc: 0.7677Epoch 1/100\n",
            "59/59 [==============================] - 56s 951ms/step - loss: 0.6884 - acc: 0.7666 - val_loss: 0.8396 - val_acc: 0.7433\n",
            "Epoch 22/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.6389 - acc: 0.7777Epoch 1/100\n",
            "59/59 [==============================] - 54s 924ms/step - loss: 0.6393 - acc: 0.7773 - val_loss: 0.6489 - val_acc: 0.8080\n",
            "Epoch 23/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.6683 - acc: 0.7743Epoch 1/100\n",
            "59/59 [==============================] - 54s 914ms/step - loss: 0.6672 - acc: 0.7742 - val_loss: 0.7292 - val_acc: 0.7902\n",
            "Epoch 24/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.6483 - acc: 0.7714Epoch 1/100\n",
            "59/59 [==============================] - 55s 940ms/step - loss: 0.6515 - acc: 0.7705 - val_loss: 0.7079 - val_acc: 0.7746\n",
            "Epoch 25/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.5877 - acc: 0.7956Epoch 1/100\n",
            "59/59 [==============================] - 53s 894ms/step - loss: 0.5848 - acc: 0.7965 - val_loss: 0.6450 - val_acc: 0.8013\n",
            "Epoch 26/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.5693 - acc: 0.7996Epoch 1/100\n",
            "59/59 [==============================] - 56s 956ms/step - loss: 0.5683 - acc: 0.7990 - val_loss: 0.7026 - val_acc: 0.8181\n",
            "Epoch 27/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.5713 - acc: 0.8008Epoch 1/100\n",
            "59/59 [==============================] - 55s 924ms/step - loss: 0.5706 - acc: 0.8002 - val_loss: 0.7044 - val_acc: 0.8092\n",
            "Epoch 28/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.5840 - acc: 0.7969Epoch 1/100\n",
            "59/59 [==============================] - 54s 918ms/step - loss: 0.5818 - acc: 0.7974 - val_loss: 0.7605 - val_acc: 0.7846\n",
            "Epoch 29/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.5440 - acc: 0.8141Epoch 1/100\n",
            "59/59 [==============================] - 55s 925ms/step - loss: 0.5432 - acc: 0.8141 - val_loss: 0.5965 - val_acc: 0.8248\n",
            "Epoch 30/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.5658 - acc: 0.8012Epoch 1/100\n",
            "59/59 [==============================] - 55s 938ms/step - loss: 0.5682 - acc: 0.8008 - val_loss: 0.6760 - val_acc: 0.8047\n",
            "Epoch 31/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.5395 - acc: 0.8035Epoch 1/100\n",
            "59/59 [==============================] - 53s 892ms/step - loss: 0.5373 - acc: 0.8044 - val_loss: 0.5589 - val_acc: 0.8359\n",
            "Epoch 32/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.5107 - acc: 0.8219Epoch 1/100\n",
            "59/59 [==============================] - 57s 965ms/step - loss: 0.5175 - acc: 0.8215 - val_loss: 0.6452 - val_acc: 0.8192\n",
            "Epoch 33/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.5214 - acc: 0.8139Epoch 1/100\n",
            "59/59 [==============================] - 54s 919ms/step - loss: 0.5227 - acc: 0.8139 - val_loss: 0.5398 - val_acc: 0.8482\n",
            "Epoch 34/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.4872 - acc: 0.8199Epoch 1/100\n",
            "59/59 [==============================] - 52s 880ms/step - loss: 0.4865 - acc: 0.8203 - val_loss: 0.5856 - val_acc: 0.8371\n",
            "Epoch 35/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.4944 - acc: 0.8164Epoch 1/100\n",
            "59/59 [==============================] - 56s 943ms/step - loss: 0.4926 - acc: 0.8169 - val_loss: 0.6376 - val_acc: 0.8326\n",
            "Epoch 36/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.4867 - acc: 0.8237Epoch 1/100\n",
            "59/59 [==============================] - 55s 926ms/step - loss: 0.4903 - acc: 0.8227 - val_loss: 0.6088 - val_acc: 0.8371\n",
            "Epoch 37/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.5003 - acc: 0.8226Epoch 1/100\n",
            "59/59 [==============================] - 55s 936ms/step - loss: 0.5013 - acc: 0.8229 - val_loss: 0.5437 - val_acc: 0.8348\n",
            "Epoch 38/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.5108 - acc: 0.8199Epoch 1/100\n",
            "59/59 [==============================] - 53s 906ms/step - loss: 0.5082 - acc: 0.8205 - val_loss: 0.5883 - val_acc: 0.8382\n",
            "Epoch 39/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.4773 - acc: 0.8219Epoch 1/100\n",
            "59/59 [==============================] - 54s 911ms/step - loss: 0.4779 - acc: 0.8212 - val_loss: 0.5425 - val_acc: 0.8516\n",
            "Epoch 40/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.4455 - acc: 0.8348Epoch 1/100\n",
            "59/59 [==============================] - 55s 930ms/step - loss: 0.4476 - acc: 0.8342 - val_loss: 0.6122 - val_acc: 0.8281\n",
            "Epoch 41/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.4546 - acc: 0.8359Epoch 1/100\n",
            "59/59 [==============================] - 53s 904ms/step - loss: 0.4555 - acc: 0.8347 - val_loss: 0.5523 - val_acc: 0.8739\n",
            "Epoch 42/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.4244 - acc: 0.8497Epoch 1/100\n",
            "59/59 [==============================] - 55s 930ms/step - loss: 0.4268 - acc: 0.8496 - val_loss: 0.5058 - val_acc: 0.8594\n",
            "Epoch 43/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.4885 - acc: 0.8324Epoch 1/100\n",
            "59/59 [==============================] - 57s 959ms/step - loss: 0.4883 - acc: 0.8315 - val_loss: 0.5572 - val_acc: 0.8504\n",
            "Epoch 44/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.4481 - acc: 0.8405Epoch 1/100\n",
            "59/59 [==============================] - 56s 942ms/step - loss: 0.4481 - acc: 0.8403 - val_loss: 0.6800 - val_acc: 0.8259\n",
            "Epoch 45/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.4249 - acc: 0.8499Epoch 1/100\n",
            "59/59 [==============================] - 54s 910ms/step - loss: 0.4248 - acc: 0.8501 - val_loss: 0.5141 - val_acc: 0.8616\n",
            "Epoch 46/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.3951 - acc: 0.8503Epoch 1/100\n",
            "59/59 [==============================] - 54s 910ms/step - loss: 0.3948 - acc: 0.8510 - val_loss: 0.4684 - val_acc: 0.8705\n",
            "Epoch 47/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.4127 - acc: 0.8483Epoch 1/100\n",
            "59/59 [==============================] - 55s 932ms/step - loss: 0.4144 - acc: 0.8488 - val_loss: 0.5649 - val_acc: 0.8482\n",
            "Epoch 48/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.4255 - acc: 0.8463Epoch 1/100\n",
            "59/59 [==============================] - 54s 912ms/step - loss: 0.4232 - acc: 0.8476 - val_loss: 0.5247 - val_acc: 0.8549\n",
            "Epoch 49/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.3936 - acc: 0.8574Epoch 1/100\n",
            "59/59 [==============================] - 55s 937ms/step - loss: 0.3925 - acc: 0.8577 - val_loss: 0.5615 - val_acc: 0.8471\n",
            "Epoch 50/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.4099 - acc: 0.8520Epoch 1/100\n",
            "59/59 [==============================] - 53s 902ms/step - loss: 0.4092 - acc: 0.8516 - val_loss: 0.5363 - val_acc: 0.8493\n",
            "Epoch 51/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.4244 - acc: 0.8521Epoch 1/100\n",
            "59/59 [==============================] - 55s 933ms/step - loss: 0.4223 - acc: 0.8528 - val_loss: 0.5337 - val_acc: 0.8694\n",
            "Epoch 52/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.4119 - acc: 0.8489Epoch 1/100\n",
            "59/59 [==============================] - 54s 920ms/step - loss: 0.4125 - acc: 0.8488 - val_loss: 0.5129 - val_acc: 0.8560\n",
            "Epoch 53/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.3845 - acc: 0.8683Epoch 1/100\n",
            "59/59 [==============================] - 55s 927ms/step - loss: 0.3839 - acc: 0.8681 - val_loss: 0.5302 - val_acc: 0.8694\n",
            "Epoch 54/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.4114 - acc: 0.8457Epoch 1/100\n",
            "59/59 [==============================] - 54s 911ms/step - loss: 0.4117 - acc: 0.8457 - val_loss: 0.4919 - val_acc: 0.8739\n",
            "Epoch 55/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.4310 - acc: 0.8460Epoch 1/100\n",
            "59/59 [==============================] - 55s 941ms/step - loss: 0.4298 - acc: 0.8465 - val_loss: 0.6025 - val_acc: 0.8337\n",
            "Epoch 56/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.3846 - acc: 0.8580Epoch 1/100\n",
            "59/59 [==============================] - 54s 919ms/step - loss: 0.3847 - acc: 0.8574 - val_loss: 0.5628 - val_acc: 0.8672\n",
            "Epoch 57/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.3574 - acc: 0.8629Epoch 1/100\n",
            "59/59 [==============================] - 54s 912ms/step - loss: 0.3550 - acc: 0.8644 - val_loss: 0.6317 - val_acc: 0.8438\n",
            "Epoch 58/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.4117 - acc: 0.8514Epoch 1/100\n",
            "59/59 [==============================] - 54s 918ms/step - loss: 0.4133 - acc: 0.8521 - val_loss: 0.8826 - val_acc: 0.7679\n",
            "Epoch 59/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.4138 - acc: 0.8495Epoch 1/100\n",
            "59/59 [==============================] - 55s 926ms/step - loss: 0.4159 - acc: 0.8492 - val_loss: 0.5048 - val_acc: 0.8627\n",
            "Epoch 60/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.3930 - acc: 0.8639Epoch 1/100\n",
            "59/59 [==============================] - 54s 923ms/step - loss: 0.3927 - acc: 0.8647 - val_loss: 0.6345 - val_acc: 0.8304\n",
            "Epoch 61/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.3913 - acc: 0.8675Epoch 1/100\n",
            "59/59 [==============================] - 50s 840ms/step - loss: 0.3887 - acc: 0.8681 - val_loss: 0.4999 - val_acc: 0.8705\n",
            "Epoch 62/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.3503 - acc: 0.8770Epoch 1/100\n",
            "59/59 [==============================] - 59s 992ms/step - loss: 0.3494 - acc: 0.8772 - val_loss: 0.4366 - val_acc: 0.8951\n",
            "Epoch 63/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.3329 - acc: 0.8795Epoch 1/100\n",
            "59/59 [==============================] - 58s 988ms/step - loss: 0.3349 - acc: 0.8788 - val_loss: 0.4649 - val_acc: 0.8728\n",
            "Epoch 64/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.3370 - acc: 0.8743Epoch 1/100\n",
            "59/59 [==============================] - 58s 978ms/step - loss: 0.3362 - acc: 0.8748 - val_loss: 0.5716 - val_acc: 0.8705\n",
            "Epoch 65/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.3441 - acc: 0.8776Epoch 1/100\n",
            "59/59 [==============================] - 57s 972ms/step - loss: 0.3424 - acc: 0.8780 - val_loss: 0.5616 - val_acc: 0.8694\n",
            "Epoch 66/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.3520 - acc: 0.8737Epoch 1/100\n",
            "59/59 [==============================] - 58s 981ms/step - loss: 0.3508 - acc: 0.8740 - val_loss: 0.5357 - val_acc: 0.8694\n",
            "Epoch 67/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.3492 - acc: 0.8732Epoch 1/100\n",
            "59/59 [==============================] - 57s 961ms/step - loss: 0.3494 - acc: 0.8740 - val_loss: 0.6139 - val_acc: 0.8717\n",
            "Epoch 68/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.3431 - acc: 0.8778Epoch 1/100\n",
            "59/59 [==============================] - 56s 953ms/step - loss: 0.3437 - acc: 0.8778 - val_loss: 0.5173 - val_acc: 0.8795\n",
            "Epoch 69/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.3258 - acc: 0.8814Epoch 1/100\n",
            "59/59 [==============================] - 56s 948ms/step - loss: 0.3274 - acc: 0.8807 - val_loss: 0.4856 - val_acc: 0.8828\n",
            "Epoch 70/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.3186 - acc: 0.8816Epoch 1/100\n",
            "59/59 [==============================] - 55s 938ms/step - loss: 0.3233 - acc: 0.8799 - val_loss: 0.4755 - val_acc: 0.8962\n",
            "Epoch 71/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.3048 - acc: 0.8876Epoch 1/100\n",
            "59/59 [==============================] - 54s 923ms/step - loss: 0.3035 - acc: 0.8885 - val_loss: 0.5533 - val_acc: 0.8616\n",
            "Epoch 72/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.3364 - acc: 0.8849Epoch 1/100\n",
            "59/59 [==============================] - 55s 929ms/step - loss: 0.3369 - acc: 0.8847 - val_loss: 0.5141 - val_acc: 0.8828\n",
            "Epoch 73/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.3050 - acc: 0.8817Epoch 1/100\n",
            "59/59 [==============================] - 54s 913ms/step - loss: 0.3085 - acc: 0.8806 - val_loss: 0.5190 - val_acc: 0.8895\n",
            "Epoch 74/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.3362 - acc: 0.8832Epoch 1/100\n",
            "59/59 [==============================] - 54s 915ms/step - loss: 0.3346 - acc: 0.8828 - val_loss: 0.5064 - val_acc: 0.8795\n",
            "Epoch 75/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.3362 - acc: 0.8772Epoch 1/100\n",
            "59/59 [==============================] - 54s 913ms/step - loss: 0.3369 - acc: 0.8769 - val_loss: 0.5025 - val_acc: 0.8884\n",
            "Epoch 76/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.3378 - acc: 0.8797Epoch 1/100\n",
            "59/59 [==============================] - 54s 915ms/step - loss: 0.3376 - acc: 0.8796 - val_loss: 0.5320 - val_acc: 0.8750\n",
            "Epoch 77/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.3344 - acc: 0.8793Epoch 1/100\n",
            "59/59 [==============================] - 54s 921ms/step - loss: 0.3342 - acc: 0.8801 - val_loss: 0.6147 - val_acc: 0.8449\n",
            "Epoch 78/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.3153 - acc: 0.8876Epoch 1/100\n",
            "59/59 [==============================] - 52s 885ms/step - loss: 0.3199 - acc: 0.8866 - val_loss: 0.5697 - val_acc: 0.8638\n",
            "Epoch 79/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.2767 - acc: 0.8949Epoch 1/100\n",
            "59/59 [==============================] - 55s 930ms/step - loss: 0.2781 - acc: 0.8951 - val_loss: 0.5508 - val_acc: 0.8705\n",
            "Epoch 80/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.3217 - acc: 0.8868Epoch 1/100\n",
            "59/59 [==============================] - 54s 909ms/step - loss: 0.3199 - acc: 0.8876 - val_loss: 0.5269 - val_acc: 0.8783\n",
            "Epoch 81/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.3211 - acc: 0.8786Epoch 1/100\n",
            "59/59 [==============================] - 55s 924ms/step - loss: 0.3196 - acc: 0.8788 - val_loss: 0.6607 - val_acc: 0.8594\n",
            "Epoch 82/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.3214 - acc: 0.8871Epoch 1/100\n",
            "59/59 [==============================] - 53s 891ms/step - loss: 0.3227 - acc: 0.8863 - val_loss: 0.5792 - val_acc: 0.8728\n",
            "Epoch 83/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.3323 - acc: 0.8844Epoch 1/100\n",
            "59/59 [==============================] - 55s 927ms/step - loss: 0.3324 - acc: 0.8845 - val_loss: 0.4513 - val_acc: 0.9029\n",
            "Epoch 84/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.3017 - acc: 0.8920Epoch 1/100\n",
            "59/59 [==============================] - 53s 907ms/step - loss: 0.3019 - acc: 0.8914 - val_loss: 0.5154 - val_acc: 0.8884\n",
            "Epoch 85/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.2814 - acc: 0.8936Epoch 1/100\n",
            "59/59 [==============================] - 54s 916ms/step - loss: 0.2803 - acc: 0.8938 - val_loss: 0.5296 - val_acc: 0.8962\n",
            "Epoch 86/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.3172 - acc: 0.8871Epoch 1/100\n",
            "59/59 [==============================] - 52s 885ms/step - loss: 0.3141 - acc: 0.8882 - val_loss: 0.4896 - val_acc: 0.8940\n",
            "Epoch 87/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.2857 - acc: 0.8884Epoch 1/100\n",
            "59/59 [==============================] - 54s 910ms/step - loss: 0.2856 - acc: 0.8884 - val_loss: 0.4893 - val_acc: 0.8884\n",
            "Epoch 88/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.2988 - acc: 0.8928Epoch 1/100\n",
            "59/59 [==============================] - 54s 911ms/step - loss: 0.2997 - acc: 0.8925 - val_loss: 0.5386 - val_acc: 0.8962\n",
            "Epoch 89/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.2838 - acc: 0.9027Epoch 1/100\n",
            "59/59 [==============================] - 56s 950ms/step - loss: 0.2856 - acc: 0.9020 - val_loss: 0.6576 - val_acc: 0.8672\n",
            "Epoch 90/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.2693 - acc: 0.9005Epoch 1/100\n",
            "59/59 [==============================] - 51s 873ms/step - loss: 0.2664 - acc: 0.9011 - val_loss: 0.5455 - val_acc: 0.8895\n",
            "Epoch 91/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.2934 - acc: 0.8990Epoch 1/100\n",
            "59/59 [==============================] - 55s 932ms/step - loss: 0.2940 - acc: 0.8988 - val_loss: 0.4680 - val_acc: 0.8929\n",
            "Epoch 92/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.2957 - acc: 0.8980Epoch 1/100\n",
            "59/59 [==============================] - 54s 914ms/step - loss: 0.2960 - acc: 0.8974 - val_loss: 0.4631 - val_acc: 0.8828\n",
            "Epoch 93/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.2790 - acc: 0.8988Epoch 1/100\n",
            "59/59 [==============================] - 53s 900ms/step - loss: 0.2766 - acc: 0.8997 - val_loss: 0.4818 - val_acc: 0.8917\n",
            "Epoch 94/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.2671 - acc: 0.9036Epoch 1/100\n",
            "59/59 [==============================] - 55s 936ms/step - loss: 0.2668 - acc: 0.9039 - val_loss: 0.5229 - val_acc: 0.8817\n",
            "Epoch 95/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.2845 - acc: 0.9012Epoch 1/100\n",
            "59/59 [==============================] - 54s 911ms/step - loss: 0.2845 - acc: 0.9008 - val_loss: 0.5900 - val_acc: 0.8895\n",
            "Epoch 96/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.3035 - acc: 0.8977Epoch 1/100\n",
            "59/59 [==============================] - 54s 918ms/step - loss: 0.3028 - acc: 0.8981 - val_loss: 0.5714 - val_acc: 0.8672\n",
            "Epoch 97/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.2807 - acc: 0.9010Epoch 1/100\n",
            "59/59 [==============================] - 53s 897ms/step - loss: 0.2811 - acc: 0.9011 - val_loss: 0.5345 - val_acc: 0.9029\n",
            "Epoch 98/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.2615 - acc: 0.9054Epoch 1/100\n",
            "59/59 [==============================] - 55s 927ms/step - loss: 0.2610 - acc: 0.9060 - val_loss: 0.4520 - val_acc: 0.9018\n",
            "Epoch 99/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.3039 - acc: 0.8966Epoch 1/100\n",
            "59/59 [==============================] - 53s 892ms/step - loss: 0.3080 - acc: 0.8947 - val_loss: 0.4951 - val_acc: 0.8850\n",
            "Epoch 100/100\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.2803 - acc: 0.9029Epoch 1/100\n",
            "59/59 [==============================] - 54s 914ms/step - loss: 0.2819 - acc: 0.9021 - val_loss: 0.4310 - val_acc: 0.9107\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fcc806beb70>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3RaQqDYdsCws",
        "colab_type": "text"
      },
      "source": [
        "With this model, we got an accuracy of over 90% after 100 Epochs after adding 2 more CNN layers.\n",
        "\n",
        "We can train the model for few more Epochs as the model's accuracy is slowly increasing or else we can try to add more CNN layers / fully connected layers to improve the model's accuracy further.\n",
        "\n",
        "We can keep trying until we are satisfied with the results given the limited resources we have or when we don't see any further scope to improve the model's accuracy any further."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RjZ0d1L3WY61",
        "colab_type": "text"
      },
      "source": [
        "# 5. Predict the accuracy for both train and validation data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JiFxI8BeBNQq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "794c3abe-f6e4-4511-d36f-e7cf637f6e53"
      },
      "source": [
        "#Using evaluate_generator on the ImageDataGenerator to predict the accuracy on training & validation Datasets\n",
        "train_loss, train_acc = model.evaluate_generator(train_generator, 3803//64)\n",
        "val_loss, val_acc = model.evaluate_generator(val_generator, 947//64)\n",
        "print('Training accuracy is', train_acc * 100, '%')\n",
        "print('Validation accuracy is', val_acc * 100, '%')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training accuracy is 93.37923526763916 %\n",
            "Validation accuracy is 90.51339030265808 %\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}