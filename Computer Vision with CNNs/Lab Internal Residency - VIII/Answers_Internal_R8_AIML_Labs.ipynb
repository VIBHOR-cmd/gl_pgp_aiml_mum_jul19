{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Answers - Internal - R8 - AIML Labs.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NFfDTfhlaEI_"
      },
      "source": [
        "# Transfer Learning MNIST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rNwbqCFRaEJC"
      },
      "source": [
        "* Train a simple convnet on the MNIST dataset the first 5 digits [0-4].\n",
        "* Freeze convolutional layers and fine-tune dense layers for the classification of digits [5-9]."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Dnzaw1i5sXF",
        "colab_type": "text"
      },
      "source": [
        "## MNIST Dataset\n",
        "The MNIST database contains 60,000 training images and 10,000 testing images taken from American Census Bureau employees and American high school students. The MNIST dataset is one of the most common datasets used for image classification and accessible from many different sources. In fact, even Tensorflow and Keras allow us to import and download the MNIST dataset directly from their API."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bpUULy1Z5sXF",
        "colab_type": "text"
      },
      "source": [
        "Let's load MNIST dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-uw1fGSV4nbR",
        "colab_type": "code",
        "outputId": "a9fdd619-29b4-499c-bfe9-04a234caeb19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KiG7IPhm5sXG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initialize the random number generator\n",
        "import random\n",
        "random.seed(0)\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZqUiJM_Z5sXL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "# the data, shuffled and split between train and test sets\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVw4wsuW5sXO",
        "colab_type": "text"
      },
      "source": [
        "X_train and X_test contain greyscale RGB codes (from 0 to 255) while y_train and y_test contains labels from 0 to 9 which represents which number they actually are."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgQ86Vhw5sXP",
        "colab_type": "text"
      },
      "source": [
        "Let's visualize some numbers using matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZwg00gO5sXQ",
        "colab_type": "code",
        "outputId": "593f3026-a6f4-4f93-b08d-5adc23a29de8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "print(\"Label: {}\".format(y_train[1000]))\n",
        "plt.imshow(X_train[1000], cmap='gray')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label: 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f670d14f1d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p64mhwp95sXS",
        "colab_type": "text"
      },
      "source": [
        "## Question 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxNAiWYd5sXT",
        "colab_type": "text"
      },
      "source": [
        "### Create two datasets\n",
        "- First having digits from 0 to 4\n",
        "- Second having digits from 5 to 9\n",
        "\n",
        "Hint: use labels to separate data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1807m1CL5sXT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Initializing empty Arrays to store the 2 Datasets\n",
        "X_train_0_4 = []\n",
        "y_train_0_4 = []\n",
        "X_test_0_4 = []\n",
        "y_test_0_4 = []\n",
        "X_train_5_9 = []\n",
        "y_train_5_9 = []\n",
        "X_test_5_9 = []\n",
        "y_test_5_9 = []\n",
        "\n",
        "#Looping through number of records in y_train\n",
        "for i in range(len(y_train)):\n",
        "  #If label is less than 5, copy the content to new Dataset having digits from 0 to 4\n",
        "  if y_train[i] < 5:\n",
        "    X_train_0_4.append(X_train[i])\n",
        "    y_train_0_4.append(y_train[i])\n",
        "  #Else, copy the content to new Dataset having digits from 5 to 9\n",
        "  else:\n",
        "    X_train_5_9.append(X_train[i])\n",
        "    y_train_5_9.append(y_train[i])\n",
        "\n",
        "#Looping through number of records in y_test\n",
        "for i in range(len(y_test)):\n",
        "  #If label is less than 5, copy the content to new Dataset having digits from 0 to 4\n",
        "  if y_test[i] < 5:\n",
        "    X_test_0_4.append(X_test[i])\n",
        "    y_test_0_4.append(y_test[i])\n",
        "  #Else, copy the content to new Dataset having digits from 5 to 9\n",
        "  else:\n",
        "    X_test_5_9.append(X_test[i])\n",
        "    y_test_5_9.append(y_test[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0x4ySkgXUTgR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Import numpy\n",
        "import numpy as np\n",
        "\n",
        "#Converting the new Datasets to Array\n",
        "X_train_0_4 = np.array(X_train_0_4)\n",
        "y_train_0_4 = np.array(y_train_0_4)\n",
        "X_test_0_4 = np.array(X_test_0_4)\n",
        "y_test_0_4 = np.array(y_test_0_4)\n",
        "X_train_5_9 = np.array(X_train_5_9)\n",
        "y_train_5_9 = np.array(y_train_5_9)\n",
        "X_test_5_9 = np.array(X_test_5_9)\n",
        "y_test_5_9 = np.array(y_test_5_9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9jKcF1z5sXV",
        "colab_type": "text"
      },
      "source": [
        "## Question 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMo7lvwQ5sXW",
        "colab_type": "text"
      },
      "source": [
        "### Print shape of the data\n",
        "- print shape of all variables of both the datasets you created"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kH7ZjEoH5sXW",
        "colab_type": "code",
        "outputId": "7b4cfd2c-4e54-44a3-d049-2deb17ced507",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "#Printing the shape of new Datasets\n",
        "print(\"Shape of X_train with digits from 0 to 4 is\", X_train_0_4.shape)\n",
        "print(\"Shape of y_train with digits from 0 to 4 is\", y_train_0_4.shape)\n",
        "print(\"Shape of X_test with digits from 0 to 4 is\", X_test_0_4.shape)\n",
        "print(\"Shape of y_test with digits from 0 to 4 is\", y_test_0_4.shape)\n",
        "print(\"Shape of X_train with digits from 5 to 9 is\", X_train_5_9.shape)\n",
        "print(\"Shape of y_train with digits from 5 to 9 is\", y_train_5_9.shape)\n",
        "print(\"Shape of X_test with digits from 5 to 9 is\", X_test_5_9.shape)\n",
        "print(\"Shape of y_test with digits from 5 to 9 is\", y_test_5_9.shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of X_train with digits from 0 to 4 is (30596, 28, 28)\n",
            "Shape of y_train with digits from 0 to 4 is (30596,)\n",
            "Shape of X_test with digits from 0 to 4 is (5139, 28, 28)\n",
            "Shape of y_test with digits from 0 to 4 is (5139,)\n",
            "Shape of X_train with digits from 5 to 9 is (29404, 28, 28)\n",
            "Shape of y_train with digits from 5 to 9 is (29404,)\n",
            "Shape of X_test with digits from 5 to 9 is (4861, 28, 28)\n",
            "Shape of y_test with digits from 5 to 9 is (4861,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUU4PkKU5sXY",
        "colab_type": "text"
      },
      "source": [
        "## Question 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4I8ajqdt5sXY",
        "colab_type": "text"
      },
      "source": [
        "### Reshape data\n",
        "- reshape first dataset\n",
        "- To be able to use the dataset in Keras, we need 4-dims numpy arrays. \n",
        "- reshape features to pass it to a Conv2D layer\n",
        "- channel = 1\n",
        "- reshape features of first dataset only\n",
        "- do not reshape labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38wgBEcz5sXa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Reshaping features of first Dataset\n",
        "X_train_0_4 = X_train_0_4.reshape(X_train_0_4.shape[0], X_train_0_4.shape[1], X_train_0_4.shape[2], 1)\n",
        "X_test_0_4 = X_test_0_4.reshape(X_test_0_4.shape[0], X_test_0_4.shape[1], X_test_0_4.shape[2], 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5H-BtNm5sXg",
        "colab_type": "text"
      },
      "source": [
        "## Question 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ahCMtCl5sXh",
        "colab_type": "text"
      },
      "source": [
        "### Normalize data\n",
        "- normalize first dataset\n",
        "- we must normalize our data as it is always required in neural network models\n",
        "- we can achieve this by dividing the RGB codes to 255 (which is the maximum RGB code minus the minimum RGB code)\n",
        "- normalize X_train and X_test\n",
        "- make sure that the values are float so that we can get decimal points after division"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4mti7pg5sXj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Normalizing features of first Dataset\n",
        "X_train_0_4 = X_train_0_4 / 255\n",
        "X_test_0_4 = X_test_0_4 / 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TfQ6545D5sXp",
        "colab_type": "text"
      },
      "source": [
        "### Print shape of data and number of images\n",
        "- for first dataset\n",
        "- print shape of X_train\n",
        "- print number of images in X_train\n",
        "- print number of images in X_test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQfQXZMo5sXp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "2a528957-8100-484b-f057-72515d5b140d"
      },
      "source": [
        "#Printing shape of X_train for first Dataset\n",
        "print(\"Shape of X_train for first Dataset is\", X_train_0_4.shape)\n",
        "\n",
        "#Printing number of images in X_train & X_test for first Dataset\n",
        "print(\"Number of Images in X_train for first Dataset is\", X_train_0_4.shape[0])\n",
        "print(\"Number of Images in X_test for first Dataset is\", X_test_0_4.shape[0])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of X_train for first Dataset is (30596, 28, 28, 1)\n",
            "Number of Images in X_train for first Dataset is 30596\n",
            "Number of Images in X_test for first Dataset is 5139\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9oFjomSh5sXu",
        "colab_type": "text"
      },
      "source": [
        "## Question 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2lEFQQNk5sXu",
        "colab_type": "text"
      },
      "source": [
        "### One-hot encode the class vector\n",
        "- encode labels of first dataset\n",
        "- convert class vectors (integers) to binary class matrix\n",
        "- convert y_train and y_test\n",
        "- number of classes: 5\n",
        "- we are doing this to use categorical_crossentropy as loss\n",
        "\n",
        "Hint: you can use tensorflow.keras.utils.to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aejx3Zb35sXv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Importing tensorflow\n",
        "import tensorflow as tf\n",
        "\n",
        "#Encoding labels of first Dataset\n",
        "y_train_0_4 = tf.keras.utils.to_categorical(y_train_0_4)\n",
        "y_test_0_4 = tf.keras.utils.to_categorical(y_test_0_4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PlkiipRA5sXw",
        "colab_type": "text"
      },
      "source": [
        "## Question 6\n",
        "We will build our model by using Keras."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KzYMC_xm5sXx",
        "colab_type": "text"
      },
      "source": [
        "### Initialize a sequential model\n",
        "- define a sequential model\n",
        "- add 2 convolutional layers\n",
        "    - no of filters: 32\n",
        "    - kernel size: 3x3\n",
        "    - activation: \"relu\"\n",
        "    - input shape: (28, 28, 1) for first layer\n",
        "- add a max pooling layer of size 2x2\n",
        "- add a dropout layer\n",
        "    - dropout layers fight with the overfitting by disregarding some of the neurons while training\n",
        "    - use dropout rate 0.2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDr-HKl-5sXx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Initialize a Sequential model\n",
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "#Adding Convolution layer\n",
        "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu', input_shape=(28,28,1)))\n",
        "\n",
        "#Adding Convolution layer\n",
        "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu'))\n",
        "\n",
        "#Adding a Maxpooling Layer of size 2x2\n",
        "model.add(tf.keras.layers.MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "#Adding a Dropout layer with dropout rate of 0.2\n",
        "model.add(tf.keras.layers.Dropout(0.2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k2RaPWiP5sXz",
        "colab_type": "text"
      },
      "source": [
        "## Question 7"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ajGIM6t5sXz",
        "colab_type": "text"
      },
      "source": [
        "### Add classification layers\n",
        "- do this after doing question 6\n",
        "- flatten the data\n",
        "    - add Flatten later\n",
        "    - flatten layers flatten 2D arrays to 1D array before building the fully connected layers\n",
        "- add 2 dense layers\n",
        "    - number of neurons in first layer: 128\n",
        "    - number of neurons in last layer: number of classes\n",
        "    - activation function in first layer: relu\n",
        "    - activation function in last layer: softmax\n",
        "    - we may experiment with any number of neurons for the first Dense layer; however, the final Dense layer must have neurons equal to the number of output classes\n",
        "- you can add a dropout layer in between, if necessary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBxWAN265sX0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Add a Flatten Layer\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "\n",
        "#Adding a Dense Layer\n",
        "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
        "\n",
        "#Adding a Dropout Layer\n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "\n",
        "#Adding a Dense Layer\n",
        "model.add(tf.keras.layers.Dense(5, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lhtm4d5K5sX1",
        "colab_type": "text"
      },
      "source": [
        "## Question 8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmXg8EaF5sX2",
        "colab_type": "text"
      },
      "source": [
        "### Compile and fit the model\n",
        "- compile your model\n",
        "    - loss: \"categorical_crossentropy\"\n",
        "    - metrics: \"accuracy\"\n",
        "    - optimizer: \"sgd\"\n",
        "- fit your model\n",
        "    - give train data - features and labels\n",
        "    - batch size: 128\n",
        "    - epochs: 10\n",
        "    - give validation data - features and labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgclxC8s5sX4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "outputId": "74b8914d-4d5c-4b45-a764-35bfdc756f60"
      },
      "source": [
        "#Compiling the model\n",
        "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "#Fitting the model on first Dataset\n",
        "model.fit(X_train_0_4, y_train_0_4, 128, 10, validation_data=(X_test_0_4, y_test_0_4))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 30596 samples, validate on 5139 samples\n",
            "Epoch 1/10\n",
            "30596/30596 [==============================] - 5s 151us/sample - loss: 0.5272 - accuracy: 0.8550 - val_loss: 0.1189 - val_accuracy: 0.9654\n",
            "Epoch 2/10\n",
            "30596/30596 [==============================] - 2s 57us/sample - loss: 0.1567 - accuracy: 0.9518 - val_loss: 0.0844 - val_accuracy: 0.9755\n",
            "Epoch 3/10\n",
            "30596/30596 [==============================] - 2s 57us/sample - loss: 0.1320 - accuracy: 0.9590 - val_loss: 0.0711 - val_accuracy: 0.9796\n",
            "Epoch 4/10\n",
            "30596/30596 [==============================] - 2s 56us/sample - loss: 0.1129 - accuracy: 0.9654 - val_loss: 0.0603 - val_accuracy: 0.9815\n",
            "Epoch 5/10\n",
            "30596/30596 [==============================] - 2s 56us/sample - loss: 0.1020 - accuracy: 0.9695 - val_loss: 0.0527 - val_accuracy: 0.9840\n",
            "Epoch 6/10\n",
            "30596/30596 [==============================] - 2s 56us/sample - loss: 0.0922 - accuracy: 0.9715 - val_loss: 0.2483 - val_accuracy: 0.8963\n",
            "Epoch 7/10\n",
            "30596/30596 [==============================] - 2s 56us/sample - loss: 0.0884 - accuracy: 0.9729 - val_loss: 0.0431 - val_accuracy: 0.9877\n",
            "Epoch 8/10\n",
            "30596/30596 [==============================] - 2s 58us/sample - loss: 0.0802 - accuracy: 0.9754 - val_loss: 0.0399 - val_accuracy: 0.9883\n",
            "Epoch 9/10\n",
            "30596/30596 [==============================] - 2s 58us/sample - loss: 0.0748 - accuracy: 0.9771 - val_loss: 0.0359 - val_accuracy: 0.9893\n",
            "Epoch 10/10\n",
            "30596/30596 [==============================] - 2s 58us/sample - loss: 0.0704 - accuracy: 0.9778 - val_loss: 0.0332 - val_accuracy: 0.9901\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f670c76cfd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSVZUu3p5sX5",
        "colab_type": "text"
      },
      "source": [
        "## Question 9"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5TQ3yLV5sX6",
        "colab_type": "text"
      },
      "source": [
        "### Evaluate model\n",
        "- evaluate your model and get accuracy\n",
        "- use test features and labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBvuD3ba5sX7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "7471e3fe-f66e-4676-b752-a2d84752bea1"
      },
      "source": [
        "#Evaluating the trained model on test features & labels for first Dataset\n",
        "model.evaluate(X_test_0_4, y_test_0_4)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5139/5139 [==============================] - 0s 84us/sample - loss: 0.0332 - accuracy: 0.9901\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.03315575023916247, 0.9900759]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8aUzOh9m5sX-",
        "colab_type": "text"
      },
      "source": [
        "## Question 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srd-YYNH5sX-",
        "colab_type": "text"
      },
      "source": [
        "## Transfer learning\n",
        "Now we will apply this model on second dataset (5-9 digits)\n",
        "\n",
        "- fix the first convolution layers so that the weights in the convolution layers dont get updated in the process of training\n",
        "- get the second dataset\n",
        "- train the last 2 dense layers\n",
        "- predict the accuracy and loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KvhdH7D55sYA",
        "colab_type": "text"
      },
      "source": [
        "### Make only dense layers trainable\n",
        "- set trainalble = False for all layers other than Dense layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "brN7VZHFaEJ4",
        "colab": {}
      },
      "source": [
        "#Freezing 2 Convolution Neural Network Layers\n",
        "for layer in model.layers[0:2]:\n",
        "    layer.trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYR9VGzO5sYE",
        "colab_type": "text"
      },
      "source": [
        "### Modify data\n",
        "- in your second data, class labels will start from 5 to 9 but for keras.utils.to_categorical the labels should start from 0\n",
        "- so you need to subtract 5 from train and test labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lC5W75L35sYF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Modifying labels for 2nd Dataset by subtracting 5 to match with keras.utils.to_categorical Labels\n",
        "y_train_5_9 -= 5\n",
        "y_test_5_9 -= 5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGY3OTBt5sYG",
        "colab_type": "text"
      },
      "source": [
        "### Reshape data\n",
        "- reshape second dataset\n",
        "- To be able to use the dataset in Keras, we need 4-dims numpy arrays. \n",
        "- reshape features to pass it to a Conv2D layer\n",
        "- channel = 1\n",
        "- reshape features of first dataset only\n",
        "- do not reshape labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0V7RUlRD5sYH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Reshaping features of second Dataset\n",
        "X_train_5_9 = X_train_5_9.reshape(X_train_5_9.shape[0], X_train_5_9.shape[1], X_train_5_9.shape[2], 1)\n",
        "X_test_5_9 = X_test_5_9.reshape(X_test_5_9.shape[0], X_test_5_9.shape[1], X_test_5_9.shape[2], 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7omqMQH5sYJ",
        "colab_type": "text"
      },
      "source": [
        "### Normalize data\n",
        "- normalize second data\n",
        "- we must normalize our data as it is always required in neural network models\n",
        "- we can achieve this by dividing the RGB codes to 255 (which is the maximum RGB code minus the minimum RGB code)\n",
        "- normalize X_train and X_test\n",
        "- make sure that the values are float so that we can get decimal points after division"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEFYNHRp5sYJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Normalizing features of second Dataset\n",
        "X_train_5_9 = X_train_5_9 / 255\n",
        "X_test_5_9 = X_test_5_9 / 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0OfdlF655sYM",
        "colab_type": "text"
      },
      "source": [
        "### Print shape of data and number of images\n",
        "- print shape of X_train\n",
        "- print number of images in X_train\n",
        "- print number of images in X_test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZEkCQ-P5sYO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "7dddaa52-b719-4e96-e27f-d831409fc251"
      },
      "source": [
        "#Printing shape of X_train for second Dataset\n",
        "print(\"Shape of X_train for first Dataset is\", X_train_5_9.shape)\n",
        "\n",
        "#Printing number of images in X_train & X_test for second Dataset\n",
        "print(\"Number of Images in X_train for first Dataset is\", X_train_5_9.shape[0])\n",
        "print(\"Number of Images in X_test for first Dataset is\", X_test_5_9.shape[0])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of X_train for first Dataset is (29404, 28, 28, 1)\n",
            "Number of Images in X_train for first Dataset is 29404\n",
            "Number of Images in X_test for first Dataset is 4861\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_3-0Qwo5sYQ",
        "colab_type": "text"
      },
      "source": [
        "### One-hot encode the class vector\n",
        "- convert class vectors (integers) to binary class matrix\n",
        "- convert y_train and y_test\n",
        "- number of classes: 5\n",
        "- we are doing this to use categorical_crossentropy as loss\n",
        "\n",
        "Hint: you can use tensorflow.keras.utils.to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k46Me5Re5sYR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Encoding labels of second Dataset\n",
        "y_train_5_9 = tf.keras.utils.to_categorical(y_train_5_9)\n",
        "y_test_5_9 = tf.keras.utils.to_categorical(y_test_5_9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9xEoW515sYS",
        "colab_type": "text"
      },
      "source": [
        "### Fit the model\n",
        "- give train data - features and labels\n",
        "- batch size: 128\n",
        "- epochs: 10\n",
        "- give validation data - features and labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6f-XAc-5sYT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "outputId": "78774f12-2b2a-4619-cf73-98fd0c6bf622"
      },
      "source": [
        "#Fitting the model on second Dataset\n",
        "model.fit(X_train_5_9, y_train_5_9, 128, 10, validation_data=(X_test_5_9, y_test_5_9))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 29404 samples, validate on 4861 samples\n",
            "Epoch 1/10\n",
            "29404/29404 [==============================] - 2s 63us/sample - loss: 0.4374 - accuracy: 0.8576 - val_loss: 0.2211 - val_accuracy: 0.9276\n",
            "Epoch 2/10\n",
            "29404/29404 [==============================] - 2s 58us/sample - loss: 0.2196 - accuracy: 0.9280 - val_loss: 0.1416 - val_accuracy: 0.9537\n",
            "Epoch 3/10\n",
            "29404/29404 [==============================] - 2s 56us/sample - loss: 0.1802 - accuracy: 0.9408 - val_loss: 0.1183 - val_accuracy: 0.9613\n",
            "Epoch 4/10\n",
            "29404/29404 [==============================] - 2s 56us/sample - loss: 0.1571 - accuracy: 0.9513 - val_loss: 0.1132 - val_accuracy: 0.9595\n",
            "Epoch 5/10\n",
            "29404/29404 [==============================] - 2s 55us/sample - loss: 0.1437 - accuracy: 0.9537 - val_loss: 0.0937 - val_accuracy: 0.9673\n",
            "Epoch 6/10\n",
            "29404/29404 [==============================] - 2s 56us/sample - loss: 0.1333 - accuracy: 0.9568 - val_loss: 0.0884 - val_accuracy: 0.9691\n",
            "Epoch 7/10\n",
            "29404/29404 [==============================] - 2s 56us/sample - loss: 0.1223 - accuracy: 0.9598 - val_loss: 0.0846 - val_accuracy: 0.9724\n",
            "Epoch 8/10\n",
            "29404/29404 [==============================] - 2s 55us/sample - loss: 0.1166 - accuracy: 0.9626 - val_loss: 0.0778 - val_accuracy: 0.9757\n",
            "Epoch 9/10\n",
            "29404/29404 [==============================] - 2s 55us/sample - loss: 0.1098 - accuracy: 0.9658 - val_loss: 0.0757 - val_accuracy: 0.9745\n",
            "Epoch 10/10\n",
            "29404/29404 [==============================] - 2s 55us/sample - loss: 0.1068 - accuracy: 0.9654 - val_loss: 0.0690 - val_accuracy: 0.9761\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f670037d940>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85ginrII5sYV",
        "colab_type": "text"
      },
      "source": [
        "### Evaluate model\n",
        "- evaluate your model and get accuracy\n",
        "- use test features and labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k11-vrsm5sYW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "549e6459-04d6-44ad-c4b4-f9a2eac6177f"
      },
      "source": [
        "#Evaluating the trained model on test features & labels for second Dataset\n",
        "model.evaluate(X_test_5_9, y_test_5_9)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4861/4861 [==============================] - 0s 81us/sample - loss: 0.0690 - accuracy: 0.9761\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.06904734532289226, 0.9761366]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTNhSDqn5sYY",
        "colab_type": "text"
      },
      "source": [
        "-----------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FU-HwvIdH0M-"
      },
      "source": [
        "# Sentiment analysis \n",
        "\n",
        "The objective of the second problem is to perform Sentiment analysis from the tweets collected from the users targeted at various mobile devices.\n",
        "Based on the tweet posted by a user (text), we will classify if the sentiment of the user targeted at a particular mobile device is positive or not."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIWWfNks5sYa",
        "colab_type": "text"
      },
      "source": [
        "## Question 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nAQDiZHRH0M_"
      },
      "source": [
        "### Read the data\n",
        "- read tweets.csv\n",
        "- use latin encoding if it gives encoding error while loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3eXGIe-SH0NA",
        "colab": {}
      },
      "source": [
        "#Importing Pandas\n",
        "import pandas as pd\n",
        "\n",
        "#Reading tweets.csv with latin encoding\n",
        "df= pd.read_csv('tweets.csv', encoding='latin')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39pqw0aE5sYe",
        "colab_type": "text"
      },
      "source": [
        "### Drop null values\n",
        "- drop all the rows with null values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BF_69oyI5sYf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Dropping rows with null values\n",
        "df.dropna(inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bm4bDiy5sYg",
        "colab_type": "text"
      },
      "source": [
        "### Print the dataframe\n",
        "- print initial 5 rows of the data\n",
        "- use df.head()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "ceSlvAVa5sYh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "6526513e-5130-4ad4-8289-16652cc26d38"
      },
      "source": [
        "#Printing initial 5 rows of the data\n",
        "df.head()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_text</th>\n",
              "      <th>emotion_in_tweet_is_directed_at</th>\n",
              "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
              "      <td>iPhone</td>\n",
              "      <td>Negative emotion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
              "      <td>iPad or iPhone App</td>\n",
              "      <td>Positive emotion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
              "      <td>iPad</td>\n",
              "      <td>Positive emotion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
              "      <td>iPad or iPhone App</td>\n",
              "      <td>Negative emotion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
              "      <td>Google</td>\n",
              "      <td>Positive emotion</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          tweet_text  ... is_there_an_emotion_directed_at_a_brand_or_product\n",
              "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...  ...                                   Negative emotion\n",
              "1  @jessedee Know about @fludapp ? Awesome iPad/i...  ...                                   Positive emotion\n",
              "2  @swonderlin Can not wait for #iPad 2 also. The...  ...                                   Positive emotion\n",
              "3  @sxsw I hope this year's festival isn't as cra...  ...                                   Negative emotion\n",
              "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...  ...                                   Positive emotion\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jcWfPVqG5sYi",
        "colab_type": "text"
      },
      "source": [
        "## Question 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBbAeip_5sYj",
        "colab_type": "text"
      },
      "source": [
        "### Preprocess data\n",
        "- convert all text to lowercase - use .lower()\n",
        "- select only numbers, alphabets, and #+_ from text - use re.sub()\n",
        "- strip all the text - use .strip()\n",
        "    - this is for removing extra spaces"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PE4Bn_YT5sYj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Importing re library for Regular Expression Engibe\n",
        "import re\n",
        "\n",
        "#Keeping only Alphanumeric valus & special characters #, + & _\n",
        "df['tweet_text'] = df['tweet_text'].apply(lambda s: re.sub('[^0-9a-z #+_]','',s))\n",
        "\n",
        "#Lower casing & stripping\n",
        "df['tweet_text'] = df['tweet_text'].apply(lambda s: s.lower().strip())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlMvbtrK5sYl",
        "colab_type": "text"
      },
      "source": [
        "print dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afocjaUn5sYm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "06d44614-f3af-4a94-df86-652f17e46b54"
      },
      "source": [
        "#Print initial 5 rows of the Data\n",
        "df.head()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_text</th>\n",
              "      <th>emotion_in_tweet_is_directed_at</th>\n",
              "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>wesley83  have a 3 ihone fter 3 hrs tweeting a...</td>\n",
              "      <td>iPhone</td>\n",
              "      <td>Negative emotion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>jessedee now about fludapp  wesome iadihone ap...</td>\n",
              "      <td>iPad or iPhone App</td>\n",
              "      <td>Positive emotion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>swonderlin an not wait for #iad 2 also hey sho...</td>\n",
              "      <td>iPad</td>\n",
              "      <td>Positive emotion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>sxsw  hope this years festival isnt as crashy ...</td>\n",
              "      <td>iPad or iPhone App</td>\n",
              "      <td>Negative emotion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>sxtxstate great stuff on ri # arissa ayer oogl...</td>\n",
              "      <td>Google</td>\n",
              "      <td>Positive emotion</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          tweet_text  ... is_there_an_emotion_directed_at_a_brand_or_product\n",
              "0  wesley83  have a 3 ihone fter 3 hrs tweeting a...  ...                                   Negative emotion\n",
              "1  jessedee now about fludapp  wesome iadihone ap...  ...                                   Positive emotion\n",
              "2  swonderlin an not wait for #iad 2 also hey sho...  ...                                   Positive emotion\n",
              "3  sxsw  hope this years festival isnt as crashy ...  ...                                   Negative emotion\n",
              "4  sxtxstate great stuff on ri # arissa ayer oogl...  ...                                   Positive emotion\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcTUnvtg5sYn",
        "colab_type": "text"
      },
      "source": [
        "## Question 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gnaeSXZ5sYo",
        "colab_type": "text"
      },
      "source": [
        "### Preprocess data\n",
        "- in column \"is_there_an_emotion_directed_at_a_brand_or_product\"\n",
        "    - select only those rows where value equal to \"positive emotion\" or \"negative emotion\"\n",
        "- find the value counts of \"positive emotion\" and \"negative emotion\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLewJh_35sYp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "76c97ce5-049a-48d4-8926-3aa5f178d33d"
      },
      "source": [
        "#Selecting only those rows where value equal to \"Positive emotion\" or \"Negative emotion\" for column 'is_there_an_emotion_directed_at_a_brand_or_product'\n",
        "df2 = df[(df['is_there_an_emotion_directed_at_a_brand_or_product'] == \"Positive emotion\") | (df['is_there_an_emotion_directed_at_a_brand_or_product'] == \"Negative emotion\")]\n",
        "\n",
        "#Finding value counts\n",
        "df2['is_there_an_emotion_directed_at_a_brand_or_product'].value_counts()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Positive emotion    2672\n",
              "Negative emotion     519\n",
              "Name: is_there_an_emotion_directed_at_a_brand_or_product, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6icGcVTE5sYz",
        "colab_type": "text"
      },
      "source": [
        "## Question 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rg0rSepj5sYz",
        "colab_type": "text"
      },
      "source": [
        "### Encode labels\n",
        "- in column \"is_there_an_emotion_directed_at_a_brand_or_product\"\n",
        "    - change \"positive emotion\" to 1\n",
        "    - change \"negative emotion\" to 0\n",
        "- use map function to replace values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YftKwFv7H0N9",
        "colab": {}
      },
      "source": [
        "#Changinf \"Positive emotion\" to 1 and \"Negative emotion\" to 0\n",
        "df2['is_there_an_emotion_directed_at_a_brand_or_product'] = df2['is_there_an_emotion_directed_at_a_brand_or_product'].map({\"Positive emotion\":1, \"Negative emotion\": 0})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sC1qSe3h5sY2",
        "colab_type": "text"
      },
      "source": [
        "## Question 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWlAN_Ts5sY2",
        "colab_type": "text"
      },
      "source": [
        "### Get feature and label\n",
        "- get column \"tweet_text\" as feature\n",
        "- get column \"is_there_an_emotion_directed_at_a_brand_or_product\" as label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9A3sOZzR5sY4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Getting column 'tweet_text' as Feature\n",
        "X = df2['tweet_text']\n",
        "\n",
        "#Getting column 'is_there_an_emotion_directed_at_a_brand_or_product' as Label\n",
        "y = df2['is_there_an_emotion_directed_at_a_brand_or_product']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3YErwYLCH0N_"
      },
      "source": [
        "### Create train and test data\n",
        "- use train_test_split to get train and test set\n",
        "- set a random_state\n",
        "- test_size: 0.25"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lNkwrGgEH0OA",
        "colab": {}
      },
      "source": [
        "#Importing train_test_split function from module model_selection in library sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#Doing a train test split with test_size of 0.25 & a random_state of 5\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMok2IX35sY8",
        "colab_type": "text"
      },
      "source": [
        "## Question 6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSqYjPuT5sY8",
        "colab_type": "text"
      },
      "source": [
        "### Vectorize data\n",
        "- create document-term matrix\n",
        "- use CountVectorizer()\n",
        "    - ngram_range: (1, 2)\n",
        "    - stop_words: 'english'\n",
        "    - min_df: 2   \n",
        "- do fit_transform on X_train\n",
        "- do transform on X_test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bb9PnnqT5sY8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Importing CountVectorizer function from feature_extraction.text submodule in sklearn library\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "#define vectorizer parameters\n",
        "vectorizer = CountVectorizer(min_df=2, stop_words='english', ngram_range=(1,2))\n",
        "\n",
        "#Creating document-term matrix\n",
        "X_train_vect = vectorizer.fit_transform(X_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCHYcKp5GkcE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Doing transform on X_test\n",
        "X_test_vect = vectorizer.transform(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qanDXve15sY_",
        "colab_type": "text"
      },
      "source": [
        "## Question 7"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMaRNFkV5sY_",
        "colab_type": "text"
      },
      "source": [
        "### Select classifier logistic regression\n",
        "- use logistic regression for predicting sentiment of the given tweet\n",
        "- initialize classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GT3dNgB55sZA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Importing LogisticRegression function from linear_model module in sklearn library\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "#Initializing Logistic Regression classifier\n",
        "model = LogisticRegression()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqQ6_HX35sZD",
        "colab_type": "text"
      },
      "source": [
        "### Fit the classifer\n",
        "- fit logistic regression classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIzvnNkq5sZD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "37ac12ae-3689-4cce-bcc2-fc92828cf9cd"
      },
      "source": [
        "#Fitting Logistic regression Classifier\n",
        "model.fit(X_train_vect, y_train)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZpMsYQF5sZF",
        "colab_type": "text"
      },
      "source": [
        "## Question 8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGnQnUww5sZF",
        "colab_type": "text"
      },
      "source": [
        "### Select classifier naive bayes\n",
        "- use naive bayes for predicting sentiment of the given tweet\n",
        "- initialize classifier\n",
        "- use MultinomialNB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2AbVYssaH0OE",
        "colab": {}
      },
      "source": [
        "#Importing MultinomialNB function from module naive_bayes in sklearn library\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "#Initializing MultinomialNB classifier\n",
        "model2 = MultinomialNB()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QEaG942m5sZI",
        "colab_type": "text"
      },
      "source": [
        "### Fit the classifer\n",
        "- fit naive bayes classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLwRBj1R5sZI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0ac80e72-9f73-4eb0-fc4c-909fb1202d12"
      },
      "source": [
        "#Fitting Naive Bayes classifier\n",
        "model2.fit(X_train_vect, y_train)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7mgwYDJ5sZM",
        "colab_type": "text"
      },
      "source": [
        "## Question 9"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZkA3tce5sZN",
        "colab_type": "text"
      },
      "source": [
        "### Make predictions on logistic regression\n",
        "- use your trained logistic regression model to make predictions on X_test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3f0M1ch5sZO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Using trained Logistic Regression model to make predictions on X_test\n",
        "y_pred = model.predict(X_test_vect)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lrIxjMUB5sZQ",
        "colab_type": "text"
      },
      "source": [
        "### Make predictions on naive bayes\n",
        "- use your trained naive bayes model to make predictions on X_test\n",
        "- use a different variable name to store predictions so that they are kept separately"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSQnwyLU5sZQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Using trained Naive Bayes model to make predictions on X_test\n",
        "y_pred2 = model2.predict(X_test_vect)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwXQUE7b5sZS",
        "colab_type": "text"
      },
      "source": [
        "## Question 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6SITIE75sZT",
        "colab_type": "text"
      },
      "source": [
        "### Calculate accuracy of logistic regression\n",
        "- check accuracy of logistic regression classifer\n",
        "- use sklearn.metrics.accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "clv2X0kKH0Ok",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ccfadeff-3816-4426-8e91-330d11985494"
      },
      "source": [
        "#Importing acuracy_score function from metrics module in sklearn library\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "#Checking accuracy of Logistic Regression Classifier\n",
        "accuracy_score(y_test, y_pred)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8596491228070176"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Fd_Gnd05sZV",
        "colab_type": "text"
      },
      "source": [
        "### Calculate accuracy of naive bayes\n",
        "- check accuracy of naive bayes classifer\n",
        "- use sklearn.metrics.accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "d32uBpHi5sZW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "38e2abe6-e7d5-44a4-bb62-58a2b659c237"
      },
      "source": [
        "#Checking accuracy of Naive Bayes Classifier\n",
        "accuracy_score(y_test, y_pred2)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8583959899749374"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    }
  ]
}