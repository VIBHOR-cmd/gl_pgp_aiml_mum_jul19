{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project- Neural Networks.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9RvFOYZlFfS",
        "colab_type": "text"
      },
      "source": [
        "**The Real Problem**\n",
        "\n",
        "Recognizing multi-digit numbers in photographs captured at street level is an important component of modern-day map making. A classic example of a corpus of such street level photographs is Google’s Street View imagery comprised of hundreds of millions of geo-located 360 degree panoramic images. The ability to automatically transcribe an address number from a geo-located patch of pixels and associate the transcribed number with a known street address helps pinpoint, with a high degree of accuracy, the location of the building it represents. \n",
        "\n",
        "More broadly, recognizing numbers in photographs is a problem of interest to the optical character recognition community. While OCR on constrained domains like document processing is well studied, arbitrary multi-character text recognition in photographs is still highly challenging. This difficulty arises due to the wide variability in the visual appearance of text in the wild on account of a large range of fonts, colors, styles, orientations, and character arrangements. The recognition problem is further complicated by environmental factors such as lighting, shadows, specularities, and occlusions as well as by image acquisition factors such as resolution, motion, and focus blurs.\n",
        "\n",
        "In this project we will use dataset with images centred around a single digit (many of the images do contain some distractors at the sides). Although we are taking a sample of the data which is simpler, it is more complex than MNIST because of the distractors.\n",
        "\n",
        "**The Street View House Numbers (SVHN) Dataset**\n",
        "\n",
        "SVHN is a real-world image dataset for developing machine learning and object recognition algorithms with minimal requirement on data formatting but comes from a significantly harder, unsolved, real world problem (recognizing digits and numbers in natural scene images). SVHN is obtained from house numbers in Google Street View images.\n",
        "\n",
        "**Link to the dataset:**\n",
        "\n",
        "https://drive.google.com/file/d/1L2-WXzguhUsCArrFUc8EEkXcj33pahoS/view?usp=sharing\n",
        "\n",
        "**Acknowledgement for the datasets.**\n",
        "\n",
        "Yuval Netzer, Tao Wang, Adam Coates, Alessandro Bissacco, Bo Wu, Andrew Y. Ng\n",
        "\n",
        "Reading Digits in Natural Images with Unsupervised Feature Learning NIPS Workshop on Deep Learning and Unsupervised Feature Learning 2011. PDF http://ufldl.stanford.edu/housenumbers as the URL for this site when necessary\n",
        "\n",
        "The objective of the project is to learn how to implement a simple image classification pipeline based on a deep neural network. The goals of this project are as follows:\n",
        "\n",
        "● Understand the basic Image Classification pipeline and the data-driven approach (train/predict stages)\n",
        "\n",
        "● Data fetching and understand the train/val/test splits. (10 points)\n",
        "\n",
        "● Implement and apply a deep neural network classifier including (feedforward neural network, RELU, activations) (20 points)\n",
        "\n",
        "● Understand and be able to implement (vectorised) backpropagation (cost stochastic gradient descent, cross entropy loss, cost functions) (20 points)\n",
        "\n",
        "● Implement batch normalization for training the neural network (5 points)\n",
        "\n",
        "● Print the classification accuracy metrics (5 points)\n",
        "\n",
        "Happy Learning!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPKO4Dd-kmsl",
        "colab_type": "code",
        "outputId": "be2c4c8a-c86b-4a06-92ef-33f508e5ef78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#For ease of working with large Dataset, we have uploaded it to Google Drive\n",
        "#So, first let's mount the drive\n",
        "\n",
        "#Importing drive module from google.colab library\n",
        "from google.colab import drive\n",
        "\n",
        "#Mount the drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8c10VCMmkGz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#To deal with h5 File, let's import h5py library\n",
        "import h5py\n",
        "\n",
        "#Load the h5 File\n",
        "f = h5py.File(\"/content/drive/My Drive/SVHN_single_grey1.h5\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WF9D_SK1mTIy",
        "colab_type": "code",
        "outputId": "cf77d0d5-c264-4716-e17d-9179b716abb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Check what all Datasets we have\n",
        "list(f.keys())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['X_test', 'X_train', 'X_val', 'y_test', 'y_train', 'y_val']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sxPKrARxYDr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Load each Datasets from the extracted h5 File\n",
        "X_test = f['X_test']\n",
        "X_train = f['X_train']\n",
        "X_val = f['X_val']\n",
        "y_test = f['y_test']\n",
        "y_train = f['y_train']\n",
        "y_val = f['y_val']"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tED6Xd43zY4Y",
        "colab_type": "code",
        "outputId": "fbbfb444-1c47-4a42-afc1-091b5e8b8f3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        }
      },
      "source": [
        "#Import tensorflow\n",
        "import tensorflow as tf\n",
        "\n",
        "#Setting random seed to 5\n",
        "tf.set_random_seed(42)\n",
        "\n",
        "#Since, we have 10 digits, let's convert the Labels to One hot encoding\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes=10)\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes=10)\n",
        "y_val = tf.keras.utils.to_categorical(y_val, num_classes=10)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLICOyFu5eGJ",
        "colab_type": "code",
        "outputId": "3a88e58f-4147-441c-9cf7-2f1fab08f383",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "#Initialize Sequential model\n",
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "#Reshape data from 2D to 1D -> 32x32 to 1024\n",
        "model.add(tf.keras.layers.Reshape((1024,),input_shape=(32,32,)))\n",
        "\n",
        "#Add 1st hidden layer\n",
        "model.add(tf.keras.layers.Dense(4096, activation='relu'))\n",
        "\n",
        "#Add 2nd hidden layer\n",
        "model.add(tf.keras.layers.Dense(1024, activation='relu'))\n",
        "\n",
        "#Add 3rd hidden layer\n",
        "model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
        "\n",
        "#Add 4th hidden layer\n",
        "model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
        "\n",
        "#Add 5th hidden layer\n",
        "model.add(tf.keras.layers.Dense(16, activation='relu'))\n",
        "\n",
        "#Add OUTPUT layer\n",
        "model.add(tf.keras.layers.Dense(10, activation='softmax'))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hD9NhZKxFHp9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Create optimizer with non-default learning rate\n",
        "sgd_optimizer = tf.keras.optimizers.SGD(lr=0.001)\n",
        "\n",
        "#Compile the model\n",
        "model.compile(optimizer=sgd_optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyip6rKjFQ6S",
        "colab_type": "code",
        "outputId": "7aa9dcc4-2293-46c0-edac-8b291b28f042",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "#Summary of the model built\n",
        "model.summary()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "reshape (Reshape)            (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 4096)              4198400   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1024)              4195328   \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 256)               262400    \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 64)                16448     \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 16)                1040      \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                170       \n",
            "=================================================================\n",
            "Total params: 8,673,786\n",
            "Trainable params: 8,673,786\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LQQMkAWFXux",
        "colab_type": "code",
        "outputId": "c40fb12d-2015-4111-853f-5bcfa7534fa8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        }
      },
      "source": [
        "#Importing numpy library\n",
        "import numpy as np\n",
        "\n",
        "#Converting validation Images into numpy Array because otherwise model.fit will encounter an Error at the end of each Epoch & come to a halt\n",
        "X_val = np.array(X_val)\n",
        "\n",
        "#Fit the model with 20 Epochs & Batch size of 1000. We need to use shuffle='batch' for h5 data.\n",
        "model.fit(X_train,y_train,          \n",
        "          validation_data=(X_val,y_val),\n",
        "          epochs=20,\n",
        "          shuffle='batch',\n",
        "          batch_size=1000)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 42000 samples, validate on 60000 samples\n",
            "Epoch 1/20\n",
            "42000/42000 [==============================] - 54s 1ms/sample - loss: 166.0383 - acc: 0.0996 - val_loss: 2.3027 - val_acc: 0.1000\n",
            "Epoch 2/20\n",
            "42000/42000 [==============================] - 53s 1ms/sample - loss: 2.3026 - acc: 0.0999 - val_loss: 2.3024 - val_acc: 0.1000\n",
            "Epoch 3/20\n",
            "42000/42000 [==============================] - 53s 1ms/sample - loss: 2.3021 - acc: 0.0999 - val_loss: 2.3015 - val_acc: 0.1000\n",
            "Epoch 4/20\n",
            "42000/42000 [==============================] - 53s 1ms/sample - loss: 2.2985 - acc: 0.0998 - val_loss: 2.2926 - val_acc: 0.1096\n",
            "Epoch 5/20\n",
            "42000/42000 [==============================] - 53s 1ms/sample - loss: 2.2865 - acc: 0.1140 - val_loss: 2.2815 - val_acc: 0.1146\n",
            "Epoch 6/20\n",
            "42000/42000 [==============================] - 54s 1ms/sample - loss: 2.2769 - acc: 0.1192 - val_loss: 2.2743 - val_acc: 0.1204\n",
            "Epoch 7/20\n",
            "42000/42000 [==============================] - 53s 1ms/sample - loss: 2.2716 - acc: 0.1212 - val_loss: 2.2709 - val_acc: 0.1235\n",
            "Epoch 8/20\n",
            "42000/42000 [==============================] - 53s 1ms/sample - loss: 2.2655 - acc: 0.1245 - val_loss: 2.2638 - val_acc: 0.1244\n",
            "Epoch 9/20\n",
            "42000/42000 [==============================] - 53s 1ms/sample - loss: 2.2627 - acc: 0.1260 - val_loss: 2.2601 - val_acc: 0.1253\n",
            "Epoch 10/20\n",
            "42000/42000 [==============================] - 53s 1ms/sample - loss: 2.2582 - acc: 0.1279 - val_loss: 2.2573 - val_acc: 0.1254\n",
            "Epoch 11/20\n",
            "42000/42000 [==============================] - 53s 1ms/sample - loss: 2.2560 - acc: 0.1288 - val_loss: 2.2536 - val_acc: 0.1284\n",
            "Epoch 12/20\n",
            "42000/42000 [==============================] - 53s 1ms/sample - loss: 2.2520 - acc: 0.1298 - val_loss: 2.2566 - val_acc: 0.1299\n",
            "Epoch 13/20\n",
            "42000/42000 [==============================] - 53s 1ms/sample - loss: 2.2490 - acc: 0.1299 - val_loss: 2.2483 - val_acc: 0.1287\n",
            "Epoch 14/20\n",
            "42000/42000 [==============================] - 53s 1ms/sample - loss: 2.2473 - acc: 0.1305 - val_loss: 2.2458 - val_acc: 0.1299\n",
            "Epoch 15/20\n",
            "42000/42000 [==============================] - 53s 1ms/sample - loss: 2.2440 - acc: 0.1315 - val_loss: 2.2433 - val_acc: 0.1303\n",
            "Epoch 16/20\n",
            "42000/42000 [==============================] - 53s 1ms/sample - loss: 2.2421 - acc: 0.1317 - val_loss: 2.2411 - val_acc: 0.1303\n",
            "Epoch 17/20\n",
            "42000/42000 [==============================] - 53s 1ms/sample - loss: 2.2400 - acc: 0.1320 - val_loss: 2.2435 - val_acc: 0.1258\n",
            "Epoch 18/20\n",
            "42000/42000 [==============================] - 53s 1ms/sample - loss: 2.2384 - acc: 0.1320 - val_loss: 2.2376 - val_acc: 0.1321\n",
            "Epoch 19/20\n",
            "42000/42000 [==============================] - 53s 1ms/sample - loss: 2.2367 - acc: 0.1325 - val_loss: 2.2360 - val_acc: 0.1308\n",
            "Epoch 20/20\n",
            "42000/42000 [==============================] - 53s 1ms/sample - loss: 2.2339 - acc: 0.1332 - val_loss: 2.2345 - val_acc: 0.1308\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f7d1d639c50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tVui5D0LObj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Predicting the values by model on test Dataset\n",
        "y_pred=model.predict_classes(X_test)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-xlELyjISnF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Converting one hot encoded test labels back to normal labels for comparision with predicted labels\n",
        "test_y=[]\n",
        "for val in y_test:\n",
        "  test_y.append(np.argmax(val))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJtWGeMgHdD4",
        "colab_type": "code",
        "outputId": "23e096f8-3690-413b-8b17-36f36cc7921a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "#Importing metrics module from sklearn library\n",
        "from sklearn import metrics\n",
        "\n",
        "#Calculate the Confusion matrix for Test data\n",
        "cm=metrics.confusion_matrix(test_y,y_pred)\n",
        "\n",
        "#Print the Confusion matrix\n",
        "cm"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   0,    0,  108,    2,    0, 1697,    0,    6,    0,    1],\n",
              "       [   0,    0,  530,    2,    0, 1289,    0,    6,    0,    1],\n",
              "       [   0,    0,  655,    1,    0, 1141,    2,    3,    0,    1],\n",
              "       [   0,    0,  282,    2,    0, 1431,    0,    4,    0,    0],\n",
              "       [   0,    0,  139,    2,    0, 1668,    0,    2,    0,    1],\n",
              "       [   0,    0,  127,    1,    0, 1631,    0,    8,    0,    1],\n",
              "       [   0,    0,  341,    1,    0, 1481,    0,    9,    0,    0],\n",
              "       [   0,    0,  685,    1,    0, 1117,    3,    1,    0,    1],\n",
              "       [   0,    0,  120,    0,    0, 1687,    0,    4,    0,    1],\n",
              "       [   0,    1,  210,    1,    0, 1576,    0,   15,    0,    1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQPYQzoeTX6Q",
        "colab_type": "text"
      },
      "source": [
        "After 20 Epochs, we can see that the model is giving just about 13% accuracy. But, given the complexity of the problem due to wide variability of the visual appearance of the digits, what's important is that slowly the model's accuracy is improving & running it for long, can give better results.\n",
        "\n",
        "Though, the accuracy can remain constrained as we can see from the Confusion matrix that the model is not at all predicting the digits 0, 4, 8 & the prediction is very poor for 1, 3, 6, 7 & 9.\n",
        "\n",
        "So, there are chances that the model's accuracy might not go above 50% even if we try for long enough."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPcC8hYhTlQ2",
        "colab_type": "text"
      },
      "source": [
        "# Understand the basic Image Classification pipeline and the data-driven approach (train/predict stages)\n",
        "In this Image Classification case study, we have some wide variability of the visual appearance of the digits.\n",
        "\n",
        "Given, it's complexity, we have tried to train the Neural network model using 5 hidden layers starting with as much as 4096 neurons to start with & slowly reducing them as we go towards the Output layer.\n",
        "\n",
        "First, we try to train the model using training dataset consisting of 42,000 records. To verify the model performance, we then validate using validate testset which in our case is bigger than training dataset with 60,000 records. It gives us a fair idea if the model is not over-fitting.\n",
        "\n",
        "Finally, we do testing with test dataset which has 18,000 records in this case.\n",
        "This is the final performance test of the model & if the testset represents true nature of images that the model is going to see in the Production, we can expect similar performance of the model in Production."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQNkqoofXaYb",
        "colab_type": "text"
      },
      "source": [
        "# Data fetching and understand the train/val/test splits\n",
        "We have the data saved in form of h5 file format. We have uploaded the data on Google drive so that we can directly mount drive on Colab & fetch the data easily. Otherwise, everytime we would resume our activity on the Project, we would have to manually upload the data on Colab Files since it temporarily allocates the resources for working on the Project when required.\n",
        "\n",
        "To retrieve the data from h5 File format, we use h5py library of Python with which we can easily retrieve the Data.\n",
        "\n",
        "Data is further divided into training, validation & test datasets identified by the Keys X_test, X_train, X_val, y_test, y_train & y_val. Here, X stands for Images stored in 32 x 32 grayscale image with each pixel having a range from 0 representing black & 255 representing white. y stands for the Image label to identify it's correct digit represented by X."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTfiBMvtZqK1",
        "colab_type": "text"
      },
      "source": [
        "# Implement and apply a deep neural network classifier including (feedforward neural network, RELU, activations)\n",
        "We have implemented & applied deep neural network classifier to classify the digits in the Images.\n",
        "\n",
        "Since, we are using fully-connected layers only for this Project, we first have to flatten the Image into 1-D array. This leads to spatial loss of information in the Image which is very important & it would have been useful to maintain it given the complexity of the problem. To do so, we have something called as Convolutional networks which first applies small image filters & slides through entire Image to identify some patterns in the numbers represented by each Image. However, this is out-of-scope of our current Project as that topic is covered altogether in another Course.\n",
        "\n",
        "Feedforward neural network is the Neural network that we have constructed but in this approach, we only move from Input layer, do some processing in each Neurons in each layers & then predict Output. We have no way to adjust our weights on the basis of loss function of the prediction vs the actual. Feedforward neural network can be used when somehow we know the weights & then directly predict the Output. This is the case after we complete training our model & when we need to predict using validation dataset or Test dataset as once the model is trained, we do not need to adjust the weights again. We can also use Feedforward neural network when we deploy the model in Production to predict the Digits in the Images as again there too we do not need to adjust the weights of the neurons of the Neural network.\n",
        "\n",
        "RELU activation is a non-linear function which we use after applying linear function determined by the weights & the bias. It gives us a way to solve non-linear problems which is the case maximum times in the real-world. This is very simple function with output being same as input if it is above 0 or 0 otherwise. One of the requirements of the activation functions is that it should be differentiable so that we can adjust the weights as it gives us the direction of the slope of the activation function which helps us determine which direction we need to go to try to reach minima. In real-sense, it is not differentiable at 0 but we can take average of slopes on positive side & negative side to take out that limitation to become an activation function. RELU activation though being simple often does better than Sigmoid activation function as the slope of Sigmoid activation function almost flattens out on extremes because of which it takes long time to arrive at the solution if it gets started with the extreme values. We have used RELU activation in our Model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PClwTFelkEq4",
        "colab_type": "text"
      },
      "source": [
        "# Understand and be able to implement (vectorised) backpropagation (cost stochastic gradient descent, cross entropy loss, cost functions)\n",
        "We have implemented (vectorised) backpropagation in our Model.\n",
        "\n",
        "Backpropagation is the technique with which we can adjust the weights & biases of the Model's neurons with an aim to minimize the loss function which helps us give better accuracy to the Model. It does so by calculating partial differentiation of Loss function with respect to each wights & biases. This helps us determine the slope of the Loss function at current values of weights & biases keeping other weights & biases constant while calculating each one of them. This gives us the direction in which we need to go & we have to go the opposite side of the direction of the slope as we are targetting to minimize the Loss function. We multiply these with learning rate which helps us determine the step size of our next adjustement of the weights. Too less the learning rate, will take lot of iterations to converge to the solution & too big the learning rate, we have risk of missing the global minima due to our huge step size. Due to complex shape of loss function, we have several local minimas & there is a risk that our model can get trapped in the local minima.\n",
        "To avoid this, we can attempt to try multiple times as with random assignment of initial weights, we have chance of reaching global minima with next run.\n",
        "\n",
        "Stochastic gradient descent is the method of adjusting the weights to minimize the loss function. Gradient is nothing but slope of the loss function. We would like to descent the slope to reach the minima so as to minimize the Loss function. Since, we take small batches into consideration every time to avoid huge computational requirement, this technique is called Stochastic Gradient Descent.\n",
        "\n",
        "We use Categorical cross entropy for categorizing the 10 digits from the Image Dataset. Cross entropy is log loss function that tries punishing the wrong predictions.\n",
        "\n",
        "Cost functions are nothing but loss functions that try to punish wrong predictions of the model & our aim is to minimize this loss function as much as possible. For regression problems, we can use Root mean square error or Mean Absolute Error as one of the Loss functions. To calculate the new adjusted weights & biases for next iteration, we do partial derivative of this Loss function with respect to each weights & biases individually. This essentially means that keeping other parameters constant, we get the direction of the slope & to minimize this loss function, we try to go in the direction opposite of the slope."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44IdJ6ADTDFJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Initialize Sequential model\n",
        "model2 = tf.keras.models.Sequential()\n",
        "\n",
        "#Reshape data from 2D to 1D -> 32x32 to 1024\n",
        "model2.add(tf.keras.layers.Reshape((1024,),input_shape=(32,32,)))\n",
        "\n",
        "#Add 1st hidden layer\n",
        "model2.add(tf.keras.layers.Dense(4096, activation='relu'))\n",
        "\n",
        "#Adding Batch normalization\n",
        "model2.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "#Add 2nd hidden layer\n",
        "model2.add(tf.keras.layers.Dense(1024, activation='relu'))\n",
        "\n",
        "#Adding Batch normalization\n",
        "model2.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "#Add 3rd hidden layer\n",
        "model2.add(tf.keras.layers.Dense(256, activation='relu'))\n",
        "\n",
        "#Adding Batch normalization\n",
        "model2.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "#Add 4th hidden layer\n",
        "model2.add(tf.keras.layers.Dense(64, activation='relu'))\n",
        "\n",
        "#Adding Batch normalization\n",
        "model2.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "#Add 5th hidden layer\n",
        "model2.add(tf.keras.layers.Dense(16, activation='relu'))\n",
        "\n",
        "#Adding Batch normalization\n",
        "model2.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "#Add OUTPUT layer\n",
        "model2.add(tf.keras.layers.Dense(10, activation='softmax'))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwPTUdt5peU7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Create optimizer with non-default learning rate\n",
        "sgd_optimizer2 = tf.keras.optimizers.SGD(lr=0.001)\n",
        "\n",
        "#Compile the model\n",
        "model2.compile(optimizer=sgd_optimizer2, loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kFdUYwZu-m5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "outputId": "48182a5b-3f55-4154-dce1-d8098890a5ba"
      },
      "source": [
        "#Summary of the model built\n",
        "model2.summary()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "reshape_1 (Reshape)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 4096)              4198400   \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 4096)              16384     \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 1024)              4195328   \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 1024)              4096      \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 256)               262400    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 256)               1024      \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 64)                16448     \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 64)                256       \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 16)                1040      \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 16)                64        \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 10)                170       \n",
            "=================================================================\n",
            "Total params: 8,695,610\n",
            "Trainable params: 8,684,698\n",
            "Non-trainable params: 10,912\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2g4nBmtOmhI9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "810c3b2f-0230-41a9-a349-8ba6c42409b8"
      },
      "source": [
        "#Fitting the new model with 100 Epochs, 1000 batch-size\n",
        "model2.fit(X_train,y_train,          \n",
        "          validation_data=(X_val,y_val),\n",
        "          epochs=100,\n",
        "          shuffle='batch',\n",
        "          batch_size=1000)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 42000 samples, validate on 60000 samples\n",
            "Epoch 1/100\n",
            "42000/42000 [==============================] - 58s 1ms/sample - loss: 2.6743 - acc: 0.1182 - val_loss: 2.7659 - val_acc: 0.1079\n",
            "Epoch 2/100\n",
            "42000/42000 [==============================] - 58s 1ms/sample - loss: 2.3946 - acc: 0.1782 - val_loss: 2.3317 - val_acc: 0.1746\n",
            "Epoch 3/100\n",
            "42000/42000 [==============================] - 57s 1ms/sample - loss: 2.2161 - acc: 0.2299 - val_loss: 2.1952 - val_acc: 0.2285\n",
            "Epoch 4/100\n",
            "42000/42000 [==============================] - 58s 1ms/sample - loss: 2.0847 - acc: 0.2726 - val_loss: 2.0799 - val_acc: 0.2793\n",
            "Epoch 5/100\n",
            "42000/42000 [==============================] - 58s 1ms/sample - loss: 1.9846 - acc: 0.3120 - val_loss: 2.0042 - val_acc: 0.3123\n",
            "Epoch 6/100\n",
            "42000/42000 [==============================] - 58s 1ms/sample - loss: 1.9076 - acc: 0.3436 - val_loss: 1.9343 - val_acc: 0.3401\n",
            "Epoch 7/100\n",
            "42000/42000 [==============================] - 58s 1ms/sample - loss: 1.8428 - acc: 0.3714 - val_loss: 1.8806 - val_acc: 0.3620\n",
            "Epoch 8/100\n",
            "42000/42000 [==============================] - 58s 1ms/sample - loss: 1.7872 - acc: 0.3946 - val_loss: 1.8302 - val_acc: 0.3807\n",
            "Epoch 9/100\n",
            "42000/42000 [==============================] - 58s 1ms/sample - loss: 1.7382 - acc: 0.4184 - val_loss: 1.7842 - val_acc: 0.4040\n",
            "Epoch 10/100\n",
            "42000/42000 [==============================] - 57s 1ms/sample - loss: 1.6966 - acc: 0.4368 - val_loss: 1.7566 - val_acc: 0.4175\n",
            "Epoch 11/100\n",
            "42000/42000 [==============================] - 57s 1ms/sample - loss: 1.6589 - acc: 0.4554 - val_loss: 1.7210 - val_acc: 0.4333\n",
            "Epoch 12/100\n",
            "42000/42000 [==============================] - 58s 1ms/sample - loss: 1.6247 - acc: 0.4718 - val_loss: 1.6880 - val_acc: 0.4497\n",
            "Epoch 13/100\n",
            "42000/42000 [==============================] - 58s 1ms/sample - loss: 1.5925 - acc: 0.4863 - val_loss: 1.6570 - val_acc: 0.4647\n",
            "Epoch 14/100\n",
            "42000/42000 [==============================] - 58s 1ms/sample - loss: 1.5611 - acc: 0.5016 - val_loss: 1.6382 - val_acc: 0.4749\n",
            "Epoch 15/100\n",
            "42000/42000 [==============================] - 57s 1ms/sample - loss: 1.5337 - acc: 0.5149 - val_loss: 1.6106 - val_acc: 0.4892\n",
            "Epoch 16/100\n",
            "42000/42000 [==============================] - 58s 1ms/sample - loss: 1.5075 - acc: 0.5274 - val_loss: 1.5858 - val_acc: 0.5020\n",
            "Epoch 17/100\n",
            "42000/42000 [==============================] - 58s 1ms/sample - loss: 1.4820 - acc: 0.5398 - val_loss: 1.5657 - val_acc: 0.5120\n",
            "Epoch 18/100\n",
            "42000/42000 [==============================] - 58s 1ms/sample - loss: 1.4586 - acc: 0.5511 - val_loss: 1.5477 - val_acc: 0.5200\n",
            "Epoch 19/100\n",
            "42000/42000 [==============================] - 58s 1ms/sample - loss: 1.4365 - acc: 0.5616 - val_loss: 1.5262 - val_acc: 0.5286\n",
            "Epoch 20/100\n",
            "42000/42000 [==============================] - 58s 1ms/sample - loss: 1.4158 - acc: 0.5723 - val_loss: 1.5103 - val_acc: 0.5394\n",
            "Epoch 21/100\n",
            "42000/42000 [==============================] - 58s 1ms/sample - loss: 1.3964 - acc: 0.5807 - val_loss: 1.4910 - val_acc: 0.5461\n",
            "Epoch 22/100\n",
            "42000/42000 [==============================] - 58s 1ms/sample - loss: 1.3771 - acc: 0.5907 - val_loss: 1.4753 - val_acc: 0.5533\n",
            "Epoch 23/100\n",
            "42000/42000 [==============================] - 58s 1ms/sample - loss: 1.3582 - acc: 0.6006 - val_loss: 1.4691 - val_acc: 0.5588\n",
            "Epoch 24/100\n",
            "42000/42000 [==============================] - 58s 1ms/sample - loss: 1.3409 - acc: 0.6091 - val_loss: 1.4434 - val_acc: 0.5686\n",
            "Epoch 25/100\n",
            "42000/42000 [==============================] - 58s 1ms/sample - loss: 1.3234 - acc: 0.6162 - val_loss: 1.4313 - val_acc: 0.5736\n",
            "Epoch 26/100\n",
            "42000/42000 [==============================] - 58s 1ms/sample - loss: 1.3067 - acc: 0.6256 - val_loss: 1.4163 - val_acc: 0.5813\n",
            "Epoch 27/100\n",
            "42000/42000 [==============================] - 58s 1ms/sample - loss: 1.2902 - acc: 0.6332 - val_loss: 1.4071 - val_acc: 0.5849\n",
            "Epoch 28/100\n",
            "42000/42000 [==============================] - 57s 1ms/sample - loss: 1.2745 - acc: 0.6390 - val_loss: 1.3927 - val_acc: 0.5902\n",
            "Epoch 29/100\n",
            "42000/42000 [==============================] - 58s 1ms/sample - loss: 1.2603 - acc: 0.6476 - val_loss: 1.3801 - val_acc: 0.5974\n",
            "Epoch 30/100\n",
            "42000/42000 [==============================] - 58s 1ms/sample - loss: 1.2461 - acc: 0.6532 - val_loss: 1.3624 - val_acc: 0.6033\n",
            "Epoch 31/100\n",
            "42000/42000 [==============================] - 58s 1ms/sample - loss: 1.2316 - acc: 0.6590 - val_loss: 1.3518 - val_acc: 0.6087\n",
            "Epoch 32/100\n",
            "42000/42000 [==============================] - 58s 1ms/sample - loss: 1.2179 - acc: 0.6656 - val_loss: 1.3394 - val_acc: 0.6134\n",
            "Epoch 33/100\n",
            "42000/42000 [==============================] - 58s 1ms/sample - loss: 1.2040 - acc: 0.6712 - val_loss: 1.3357 - val_acc: 0.6156\n",
            "Epoch 34/100\n",
            "42000/42000 [==============================] - 58s 1ms/sample - loss: 1.1908 - acc: 0.6754 - val_loss: 1.3210 - val_acc: 0.6210\n",
            "Epoch 35/100\n",
            "42000/42000 [==============================] - 58s 1ms/sample - loss: 1.1776 - acc: 0.6817 - val_loss: 1.3095 - val_acc: 0.6250\n",
            "Epoch 36/100\n",
            "42000/42000 [==============================] - 58s 1ms/sample - loss: 1.1651 - acc: 0.6865 - val_loss: 1.2956 - val_acc: 0.6303\n",
            "Epoch 37/100\n",
            "42000/42000 [==============================] - 57s 1ms/sample - loss: 1.1526 - acc: 0.6917 - val_loss: 1.2947 - val_acc: 0.6325\n",
            "Epoch 38/100\n",
            "42000/42000 [==============================] - 57s 1ms/sample - loss: 1.1405 - acc: 0.6974 - val_loss: 1.2787 - val_acc: 0.6380\n",
            "Epoch 39/100\n",
            "42000/42000 [==============================] - 58s 1ms/sample - loss: 1.1286 - acc: 0.7010 - val_loss: 1.2730 - val_acc: 0.6406\n",
            "Epoch 40/100\n",
            "42000/42000 [==============================] - 58s 1ms/sample - loss: 1.1166 - acc: 0.7070 - val_loss: 1.2594 - val_acc: 0.6456\n",
            "Epoch 41/100\n",
            "42000/42000 [==============================] - 58s 1ms/sample - loss: 1.1054 - acc: 0.7100 - val_loss: 1.2473 - val_acc: 0.6490\n",
            "Epoch 42/100\n",
            "42000/42000 [==============================] - 57s 1ms/sample - loss: 1.0940 - acc: 0.7151 - val_loss: 1.2353 - val_acc: 0.6534\n",
            "Epoch 43/100\n",
            "42000/42000 [==============================] - 57s 1ms/sample - loss: 1.0825 - acc: 0.7195 - val_loss: 1.2318 - val_acc: 0.6571\n",
            "Epoch 44/100\n",
            "42000/42000 [==============================] - 58s 1ms/sample - loss: 1.0712 - acc: 0.7236 - val_loss: 1.2207 - val_acc: 0.6601\n",
            "Epoch 45/100\n",
            "42000/42000 [==============================] - 58s 1ms/sample - loss: 1.0608 - acc: 0.7281 - val_loss: 1.2093 - val_acc: 0.6641\n",
            "Epoch 46/100\n",
            "42000/42000 [==============================] - 58s 1ms/sample - loss: 1.0500 - acc: 0.7324 - val_loss: 1.2010 - val_acc: 0.6678\n",
            "Epoch 47/100\n",
            "42000/42000 [==============================] - 58s 1ms/sample - loss: 1.0396 - acc: 0.7372 - val_loss: 1.1925 - val_acc: 0.6704\n",
            "Epoch 48/100\n",
            "42000/42000 [==============================] - 58s 1ms/sample - loss: 1.0290 - acc: 0.7402 - val_loss: 1.1830 - val_acc: 0.6731\n",
            "Epoch 49/100\n",
            "42000/42000 [==============================] - 58s 1ms/sample - loss: 1.0191 - acc: 0.7427 - val_loss: 1.1815 - val_acc: 0.6723\n",
            "Epoch 50/100\n",
            "42000/42000 [==============================] - 58s 1ms/sample - loss: 1.0096 - acc: 0.7465 - val_loss: 1.1685 - val_acc: 0.6796\n",
            "Epoch 51/100\n",
            "42000/42000 [==============================] - 58s 1ms/sample - loss: 0.9998 - acc: 0.7504 - val_loss: 1.1618 - val_acc: 0.6820\n",
            "Epoch 52/100\n",
            "42000/42000 [==============================] - 58s 1ms/sample - loss: 0.9899 - acc: 0.7532 - val_loss: 1.1501 - val_acc: 0.6846\n",
            "Epoch 53/100\n",
            "42000/42000 [==============================] - 58s 1ms/sample - loss: 0.9804 - acc: 0.7573 - val_loss: 1.1488 - val_acc: 0.6866\n",
            "Epoch 54/100\n",
            "42000/42000 [==============================] - 58s 1ms/sample - loss: 0.9708 - acc: 0.7611 - val_loss: 1.1365 - val_acc: 0.6903\n",
            "Epoch 55/100\n",
            "42000/42000 [==============================] - 58s 1ms/sample - loss: 0.9613 - acc: 0.7631 - val_loss: 1.1309 - val_acc: 0.6914\n",
            "Epoch 56/100\n",
            "42000/42000 [==============================] - 58s 1ms/sample - loss: 0.9520 - acc: 0.7673 - val_loss: 1.1263 - val_acc: 0.6948\n",
            "Epoch 57/100\n",
            "42000/42000 [==============================] - 58s 1ms/sample - loss: 0.9428 - acc: 0.7702 - val_loss: 1.1163 - val_acc: 0.6975\n",
            "Epoch 58/100\n",
            "42000/42000 [==============================] - 58s 1ms/sample - loss: 0.9333 - acc: 0.7724 - val_loss: 1.1081 - val_acc: 0.6995\n",
            "Epoch 59/100\n",
            "42000/42000 [==============================] - 58s 1ms/sample - loss: 0.9249 - acc: 0.7745 - val_loss: 1.1042 - val_acc: 0.7009\n",
            "Epoch 60/100\n",
            "42000/42000 [==============================] - 58s 1ms/sample - loss: 0.9161 - acc: 0.7790 - val_loss: 1.0964 - val_acc: 0.7036\n",
            "Epoch 61/100\n",
            "42000/42000 [==============================] - 58s 1ms/sample - loss: 0.9078 - acc: 0.7820 - val_loss: 1.0836 - val_acc: 0.7075\n",
            "Epoch 62/100\n",
            "42000/42000 [==============================] - 57s 1ms/sample - loss: 0.8991 - acc: 0.7844 - val_loss: 1.0803 - val_acc: 0.7081\n",
            "Epoch 63/100\n",
            "42000/42000 [==============================] - 58s 1ms/sample - loss: 0.8917 - acc: 0.7868 - val_loss: 1.0676 - val_acc: 0.7123\n",
            "Epoch 64/100\n",
            "42000/42000 [==============================] - 58s 1ms/sample - loss: 0.8831 - acc: 0.7885 - val_loss: 1.0668 - val_acc: 0.7130\n",
            "Epoch 65/100\n",
            "42000/42000 [==============================] - 58s 1ms/sample - loss: 0.8744 - acc: 0.7936 - val_loss: 1.0610 - val_acc: 0.7148\n",
            "Epoch 66/100\n",
            "42000/42000 [==============================] - 58s 1ms/sample - loss: 0.8665 - acc: 0.7946 - val_loss: 1.0536 - val_acc: 0.7174\n",
            "Epoch 67/100\n",
            "42000/42000 [==============================] - 57s 1ms/sample - loss: 0.8581 - acc: 0.7978 - val_loss: 1.0498 - val_acc: 0.7185\n",
            "Epoch 68/100\n",
            "42000/42000 [==============================] - 58s 1ms/sample - loss: 0.8505 - acc: 0.7999 - val_loss: 1.0376 - val_acc: 0.7230\n",
            "Epoch 69/100\n",
            "42000/42000 [==============================] - 58s 1ms/sample - loss: 0.8424 - acc: 0.8028 - val_loss: 1.0348 - val_acc: 0.7243\n",
            "Epoch 70/100\n",
            "42000/42000 [==============================] - 58s 1ms/sample - loss: 0.8346 - acc: 0.8056 - val_loss: 1.0276 - val_acc: 0.7247\n",
            "Epoch 71/100\n",
            "42000/42000 [==============================] - 58s 1ms/sample - loss: 0.8272 - acc: 0.8075 - val_loss: 1.0213 - val_acc: 0.7265\n",
            "Epoch 72/100\n",
            "42000/42000 [==============================] - 58s 1ms/sample - loss: 0.8195 - acc: 0.8106 - val_loss: 1.0127 - val_acc: 0.7308\n",
            "Epoch 73/100\n",
            "42000/42000 [==============================] - 57s 1ms/sample - loss: 0.8127 - acc: 0.8128 - val_loss: 1.0102 - val_acc: 0.7326\n",
            "Epoch 74/100\n",
            "42000/42000 [==============================] - 58s 1ms/sample - loss: 0.8053 - acc: 0.8150 - val_loss: 1.0020 - val_acc: 0.7346\n",
            "Epoch 75/100\n",
            "42000/42000 [==============================] - 58s 1ms/sample - loss: 0.7976 - acc: 0.8169 - val_loss: 1.0001 - val_acc: 0.7341\n",
            "Epoch 76/100\n",
            "42000/42000 [==============================] - 58s 1ms/sample - loss: 0.7907 - acc: 0.8191 - val_loss: 0.9937 - val_acc: 0.7375\n",
            "Epoch 77/100\n",
            "42000/42000 [==============================] - 58s 1ms/sample - loss: 0.7831 - acc: 0.8219 - val_loss: 0.9846 - val_acc: 0.7408\n",
            "Epoch 78/100\n",
            "42000/42000 [==============================] - 58s 1ms/sample - loss: 0.7771 - acc: 0.8233 - val_loss: 0.9823 - val_acc: 0.7412\n",
            "Epoch 79/100\n",
            "42000/42000 [==============================] - 58s 1ms/sample - loss: 0.7702 - acc: 0.8252 - val_loss: 0.9773 - val_acc: 0.7421\n",
            "Epoch 80/100\n",
            "42000/42000 [==============================] - 58s 1ms/sample - loss: 0.7638 - acc: 0.8275 - val_loss: 0.9711 - val_acc: 0.7453\n",
            "Epoch 81/100\n",
            "42000/42000 [==============================] - 58s 1ms/sample - loss: 0.7566 - acc: 0.8301 - val_loss: 0.9608 - val_acc: 0.7469\n",
            "Epoch 82/100\n",
            "42000/42000 [==============================] - 58s 1ms/sample - loss: 0.7494 - acc: 0.8330 - val_loss: 0.9598 - val_acc: 0.7475\n",
            "Epoch 83/100\n",
            "42000/42000 [==============================] - 58s 1ms/sample - loss: 0.7426 - acc: 0.8352 - val_loss: 0.9506 - val_acc: 0.7505\n",
            "Epoch 84/100\n",
            "42000/42000 [==============================] - 58s 1ms/sample - loss: 0.7356 - acc: 0.8371 - val_loss: 0.9524 - val_acc: 0.7489\n",
            "Epoch 85/100\n",
            "42000/42000 [==============================] - 61s 1ms/sample - loss: 0.7293 - acc: 0.8391 - val_loss: 0.9411 - val_acc: 0.7531\n",
            "Epoch 86/100\n",
            "42000/42000 [==============================] - 58s 1ms/sample - loss: 0.7232 - acc: 0.8413 - val_loss: 0.9374 - val_acc: 0.7540\n",
            "Epoch 87/100\n",
            "42000/42000 [==============================] - 58s 1ms/sample - loss: 0.7168 - acc: 0.8433 - val_loss: 0.9334 - val_acc: 0.7564\n",
            "Epoch 88/100\n",
            "42000/42000 [==============================] - 58s 1ms/sample - loss: 0.7104 - acc: 0.8443 - val_loss: 0.9322 - val_acc: 0.7571\n",
            "Epoch 89/100\n",
            "42000/42000 [==============================] - 58s 1ms/sample - loss: 0.7048 - acc: 0.8464 - val_loss: 0.9262 - val_acc: 0.7578\n",
            "Epoch 90/100\n",
            "42000/42000 [==============================] - 58s 1ms/sample - loss: 0.6985 - acc: 0.8481 - val_loss: 0.9191 - val_acc: 0.7596\n",
            "Epoch 91/100\n",
            "42000/42000 [==============================] - 58s 1ms/sample - loss: 0.6924 - acc: 0.8500 - val_loss: 0.9129 - val_acc: 0.7623\n",
            "Epoch 92/100\n",
            "42000/42000 [==============================] - 58s 1ms/sample - loss: 0.6862 - acc: 0.8525 - val_loss: 0.9100 - val_acc: 0.7637\n",
            "Epoch 93/100\n",
            "42000/42000 [==============================] - 58s 1ms/sample - loss: 0.6812 - acc: 0.8542 - val_loss: 0.9075 - val_acc: 0.7637\n",
            "Epoch 94/100\n",
            "42000/42000 [==============================] - 58s 1ms/sample - loss: 0.6750 - acc: 0.8554 - val_loss: 0.9063 - val_acc: 0.7643\n",
            "Epoch 95/100\n",
            "42000/42000 [==============================] - 58s 1ms/sample - loss: 0.6689 - acc: 0.8570 - val_loss: 0.9017 - val_acc: 0.7674\n",
            "Epoch 96/100\n",
            "42000/42000 [==============================] - 58s 1ms/sample - loss: 0.6629 - acc: 0.8588 - val_loss: 0.8912 - val_acc: 0.7687\n",
            "Epoch 97/100\n",
            "42000/42000 [==============================] - 58s 1ms/sample - loss: 0.6570 - acc: 0.8600 - val_loss: 0.8877 - val_acc: 0.7694\n",
            "Epoch 98/100\n",
            "42000/42000 [==============================] - 58s 1ms/sample - loss: 0.6516 - acc: 0.8626 - val_loss: 0.8820 - val_acc: 0.7699\n",
            "Epoch 99/100\n",
            "42000/42000 [==============================] - 58s 1ms/sample - loss: 0.6461 - acc: 0.8644 - val_loss: 0.8800 - val_acc: 0.7735\n",
            "Epoch 100/100\n",
            "42000/42000 [==============================] - 58s 1ms/sample - loss: 0.6402 - acc: 0.8652 - val_loss: 0.8788 - val_acc: 0.7719\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f7d0c3420f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lf75HLCg4G92",
        "colab_type": "text"
      },
      "source": [
        "# Implement batch normalization for training the neural network\n",
        "We have used batch normalization in the above model.\n",
        "\n",
        "Batch normalization is the technique with which we can increase the speed, accuracy & stability of the model.\n",
        "\n",
        "And as we can see ourselves, though it is taking 58s on an average for completing 1 epoch with Batch normalization vs 53s on an average for each epoch without Batch normalization, after 20 Epochs, we were getting merely 13% accuracy without using Batch normalization as compared to over 17% after just the 2nd Epoch. Slight increase in time for each epoch is because the model has to learn few more mean & shift parameters for each Batch normalization layer & it also involves additional computation for normalizing the data.\n",
        "\n",
        "But, this increase in time per Epoch is negligible as compared to the benefits we are getting using the Batch normalization including the speed of convergence for such a complex model involving more than 8 million parameters to be learnt.\n",
        "\n",
        "There is bit of overfitting but we can tackle it with regularization techniques like introducing Dropout layer in between to randomly drop output of some neurons, using L1 & L2 regularization to avoid weights to take very high values which would overwhelm other weights, Data augmentation to artificially increase the training set & techniques like Early stopping if validation accuracy starts deteriorating after certain number of iterations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_EyTExp7CEy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Predicting on Test dataset with new Model\n",
        "y_pred2=model2.predict_classes(X_test)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2wcjgL37EwV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "ed8cba78-1f93-41c5-b2da-d9d064e6a291"
      },
      "source": [
        "#Calculating confusion matrix for Test dataset\n",
        "cm2=metrics.confusion_matrix(test_y,y_pred2)\n",
        "\n",
        "#Printing the confusion matrix\n",
        "cm2"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1218,   64,   21,   51,   69,   33,  103,   64,   44,  147],\n",
              "       [  49, 1291,   90,   35,   68,   35,   42,  128,   37,   53],\n",
              "       [  46,   85, 1173,  106,   53,   41,   21,  166,   53,   59],\n",
              "       [  51,   60,   96,  974,   21,  188,   48,  142,   70,   69],\n",
              "       [  61,   96,   60,   17, 1273,   30,  105,   64,   38,   68],\n",
              "       [  44,   37,   40,  210,   23, 1021,   98,   98,   81,  116],\n",
              "       [ 120,   59,   44,   26,   89,  111, 1149,   55,  103,   76],\n",
              "       [  44,  103,   76,   75,   27,   41,   16, 1360,   21,   45],\n",
              "       [  79,   93,   54,   79,   50,   88,  140,   57, 1028,  144],\n",
              "       [ 140,   97,   42,   68,   44,   81,   43,   87,  107, 1095]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmmbzGqM-ZXZ",
        "colab_type": "text"
      },
      "source": [
        "# Print the classification accuracy metrics\n",
        "We have printed the confusion matrix above and as we can see, the overall test accuracy is much better as compared to previous model. After 100 Epochs, we are getting an accuracy of 64.34%.\n",
        "\n",
        "There is still scope of improvement as we can see that the model has started overfitting training dataset with 86.52% of accuracy on training dataset after 100 Epochs.\n",
        "\n",
        "We can use some of the Regularization techniques to avoid the problem of overfitting in Neural networks."
      ]
    }
  ]
}