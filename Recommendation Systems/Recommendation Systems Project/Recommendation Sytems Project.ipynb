{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation Systems | Project\n",
    "\n",
    "**Problem Statement -**\n",
    "\n",
    "Build your own recommendation system for products on an e-commerce website like Amazon.com.\n",
    "\n",
    "Dataset Link -\n",
    "\n",
    "https://drive.google.com/file/d/1ClBptsK3V5KgKXtK2GSRzFNAW7GnTPDW/view?usp=sharing\n",
    "\n",
    "**Dataset columns** - first three columns are userId, productId, and ratings and the fourth column is timestamp. You can discard the timestamp column as in this case you may not need to use it.\n",
    "\n",
    "**Source** - Amazon Reviews data (http://jmcauley.ucsd.edu/data/amazon/) The repository has several datasets. For this case study, we are using the Electronics dataset.\n",
    "\n",
    "Please do the analysis based on steps( 1 to 8) as given below -\n",
    "\n",
    "**Steps** -\n",
    "1. Read and explore the given dataset. ( Rename column/add headers, plot histograms, find data characteristics)\n",
    "2. Take a subset of the dataset to make it less sparse/ denser. ( For example, keep the users only who has given 50 or more number of ratings )\n",
    "3. Split the data randomly into train and test dataset. ( For example, split it in 70/30 ratio)\n",
    "4. Build Popularity Recommender model.\n",
    "5. Build Collaborative Filtering model.\n",
    "6. Evaluate both the models. ( Once the model is trained on the training data, it can be used to compute the error (like RMSE) on predictions made on the test data.) You can also use a different method to evaluate the models.\n",
    "7. Get top - K ( K = 5) recommendations. Since our goal is to recommend new products to each user based on his/her habits, we will recommend 5 new products.\n",
    "8. Summarise your insights.\n",
    "\n",
    "Please Note -\n",
    "\n",
    "● If you are facing any memory issue while working on this project, create a small subset (Let’s say 10% of data) and work on it.\n",
    "\n",
    "● If you are stuck at the model evaluation part of this project.\n",
    "\n",
    "Please refer to below links -\n",
    "1. https://surprise.readthedocs.io/en/stable/accuracy.html\n",
    "2. http://surpriselib.com/ - Getting started, example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Read and explore the given dataset. ( Rename column/add headers, plot histograms, find data characteristics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing common libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AKM1MP6P0OYPR</td>\n",
       "      <td>0132793040</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1365811200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A2CX7LUOHB2NDG</td>\n",
       "      <td>0321732944</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1341100800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A2NWSAGRHCP8N5</td>\n",
       "      <td>0439886341</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1367193600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A2WNBOD3WNDNKT</td>\n",
       "      <td>0439886341</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1374451200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A1GI0U4ZRJA8WN</td>\n",
       "      <td>0439886341</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1334707200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0           1    2           3\n",
       "0   AKM1MP6P0OYPR  0132793040  5.0  1365811200\n",
       "1  A2CX7LUOHB2NDG  0321732944  5.0  1341100800\n",
       "2  A2NWSAGRHCP8N5  0439886341  1.0  1367193600\n",
       "3  A2WNBOD3WNDNKT  0439886341  3.0  1374451200\n",
       "4  A1GI0U4ZRJA8WN  0439886341  1.0  1334707200"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read the dataset\n",
    "df = pd.read_csv('ratings_Electronics.csv', header=None)\n",
    "\n",
    "#Checking top 5 records to check if dataset is loaded properly\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>productId</th>\n",
       "      <th>ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AKM1MP6P0OYPR</td>\n",
       "      <td>0132793040</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A2CX7LUOHB2NDG</td>\n",
       "      <td>0321732944</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A2NWSAGRHCP8N5</td>\n",
       "      <td>0439886341</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A2WNBOD3WNDNKT</td>\n",
       "      <td>0439886341</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A1GI0U4ZRJA8WN</td>\n",
       "      <td>0439886341</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           userId   productId  ratings\n",
       "0   AKM1MP6P0OYPR  0132793040      5.0\n",
       "1  A2CX7LUOHB2NDG  0321732944      5.0\n",
       "2  A2NWSAGRHCP8N5  0439886341      1.0\n",
       "3  A2WNBOD3WNDNKT  0439886341      3.0\n",
       "4  A1GI0U4ZRJA8WN  0439886341      1.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Adding columns to the Dataset\n",
    "df.columns = ['userId', 'productId', 'ratings', 'timestamp']\n",
    "\n",
    "#Dropping timestamp column as it is not needed for our Analysis\n",
    "df.drop('timestamp', axis=1, inplace=True)\n",
    "\n",
    "#Checking the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plotting histograms\n",
    "df.hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7824482 entries, 0 to 7824481\n",
      "Data columns (total 3 columns):\n",
      "userId       object\n",
      "productId    object\n",
      "ratings      float64\n",
      "dtypes: float64(1), object(2)\n",
      "memory usage: 179.1+ MB\n"
     ]
    }
   ],
   "source": [
    "#Checking dataset info\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0    4347541\n",
       "4.0    1485781\n",
       "1.0     901765\n",
       "3.0     633073\n",
       "2.0     456322\n",
       "Name: ratings, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#userId & productId are object type as expected. But, ratings are float instead of int\n",
    "#So, let's check unique values in ratings column to see why the ratings column is float\n",
    "df['ratings'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "userId       7824482\n",
       "productId    7824482\n",
       "ratings      7824482\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#As we can see, ratings column has ratings 1, 2, 3, 4 & 5 only but they are stored as float which is OK for us.\n",
    "#Let's check if we have any missing values\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary:\n",
    "We loaded the User ratings for Electronics products which has ratings for almost 8 Lakh which is good large dataset for our Analysis. We dropped timestamp column as we do not need it for our Analysis.\n",
    "\n",
    "From the Histogram & value_counts, we can see that more than 50% people rate the products as 5 with decreasing trend for lower ratings with an exception for rating 1 which few unhappy Customers would have given.\n",
    "\n",
    "We don't have any missing values & the dataset is good to proceed further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Take a subset of the dataset to make it less sparse/ denser. ( For example, keep the users only who has given 50 or more number of ratings )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>productId</th>\n",
       "      <th>ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>A3BY5KCNQZXV5U</td>\n",
       "      <td>0594451647</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>AT09WGFUM934H</td>\n",
       "      <td>0594481813</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>A32HSNCNPRUMTR</td>\n",
       "      <td>0970407998</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>A17HMM1M7T9PJ1</td>\n",
       "      <td>0970407998</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>A3CLWR1UUZT6TG</td>\n",
       "      <td>0972683275</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             userId   productId  ratings\n",
       "94   A3BY5KCNQZXV5U  0594451647      5.0\n",
       "118   AT09WGFUM934H  0594481813      3.0\n",
       "177  A32HSNCNPRUMTR  0970407998      1.0\n",
       "178  A17HMM1M7T9PJ1  0970407998      4.0\n",
       "492  A3CLWR1UUZT6TG  0972683275      5.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating new DataFrame consisting of userID & if they have rated at least 50 Electronics products or not\n",
    "ratings_50 = pd.DataFrame(df.groupby(by='userId')['ratings'].count() >= 50)\n",
    "\n",
    "#Extract only userID who have rated at least 100 books\n",
    "ratings_50 = pd.DataFrame(ratings_50[ratings_50['ratings'] == True].index)\n",
    "\n",
    "#Finding records in this new Dataset that are there in ratings dataset\n",
    "df_subset = df[df['userId'].isin(ratings_50['userId'])].dropna()\n",
    "\n",
    "#delete temporary Dataset created\n",
    "del ratings_50\n",
    "\n",
    "#Checking new dataset\n",
    "df_subset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125871, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking size of new Dataset\n",
    "df_subset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary:\n",
    "We have created a subset of original dataset to make it less sparser by keeping only Users who have rated at least 50 Electronics Products.\n",
    "\n",
    "By doing this, we have created dataset consisting of only 1.6% data of original data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Split the data randomly into train and test dataset. ( For example, split it in 70/30 ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing train_test_split submodule from model_selection module in sklearn library\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Splitting the data into 70:30 ratio for training & testing\n",
    "df_train, df_test = train_test_split(df_subset, test_size=0.30, random_state=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary:\n",
    "We split the Dataset into Training & Testing Datasets randomly in the ratio 70:30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Build Popularity Recommender model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grouping by productId & counting records then sort in descending order\n",
    "recommend_train = pd.DataFrame(df_train.groupby(by='productId').count()['userId']).sort_values(by = 'userId', ascending=False)\n",
    "\n",
    "#Rename column to count\n",
    "recommend_train.columns = ['count']\n",
    "\n",
    "#Reset index to get productId as column\n",
    "recommend_train.reset_index(inplace=True)\n",
    "\n",
    "#Add new column rank & rank it by descending order of count\n",
    "recommend_train['rank'] = recommend_train['count'].rank(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>productId</th>\n",
       "      <th>count</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B0088CJT4U</td>\n",
       "      <td>141</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B003ES5ZUU</td>\n",
       "      <td>130</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B000N99BBC</td>\n",
       "      <td>118</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B007WTAJTO</td>\n",
       "      <td>117</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B00829TIEK</td>\n",
       "      <td>105</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>B008DWCRQW</td>\n",
       "      <td>102</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>B00829THK0</td>\n",
       "      <td>96</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>B002R5AM7C</td>\n",
       "      <td>90</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>B002SZEOLG</td>\n",
       "      <td>80</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>B00834SJNA</td>\n",
       "      <td>79</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    productId  count  rank\n",
       "0  B0088CJT4U    141   1.0\n",
       "1  B003ES5ZUU    130   2.0\n",
       "2  B000N99BBC    118   3.0\n",
       "3  B007WTAJTO    117   4.0\n",
       "4  B00829TIEK    105   5.0\n",
       "5  B008DWCRQW    102   6.0\n",
       "6  B00829THK0     96   7.0\n",
       "7  B002R5AM7C     90   8.0\n",
       "8  B002SZEOLG     80   9.0\n",
       "9  B00834SJNA     79  10.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Printing Top 10 popular Electronics Products\n",
    "recommend_train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary:\n",
    "We have created Popularity based Recommendation model which shows top N Electronics products based on it's popularity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Build Collaborative Filtering model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.knns.KNNWithMeans at 0x1927695eb48>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise import KNNWithMeans, Dataset, Reader\n",
    "\n",
    "# Use user_based true/false to switch between user-based or item-based collaborative filtering\n",
    "algo = KNNWithMeans(k=50, sim_options={'name': 'cosine', 'user_based': True})\n",
    "\n",
    "#Putting scale as 1 to 5 for the reader\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "\n",
    "#Converting Pandas DataFrame into surprise Dataset\n",
    "data_train = Dataset.load_from_df(df_train[['userId', 'productId', 'ratings']], reader)\n",
    "\n",
    "#Since, we have already split data into train & test, we can use full training data as trainset\n",
    "data_train = data_train.build_full_trainset()\n",
    "\n",
    "#Training user-based Collaborative model\n",
    "algo.fit(data_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary:\n",
    "We have built the user-based Collaborative model using KNNWithMeans using cosine similarity as the distance formula"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Evaluate both the models. ( Once the model is trained on the training data, it can be used to compute the error (like RMSE) on predictions made on the test data.) You can also use a different method to evaluate the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's build popularity based model for Test data & then compare it with Training data to evaluate it's performance\n",
    "#Grouping by productId & counting records then sort in descending order\n",
    "recommend_test = pd.DataFrame(df_test.groupby(by='productId').count()['userId']).sort_values(by = 'userId', ascending=False)\n",
    "\n",
    "#Rename column to count\n",
    "recommend_test.columns = ['count']\n",
    "\n",
    "#Reset index to get productId as column\n",
    "recommend_test.reset_index(inplace=True)\n",
    "\n",
    "#Add new column rank & rank it by descending order of count\n",
    "recommend_test['rank'] = recommend_test['count'].rank(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>productId</th>\n",
       "      <th>count_x</th>\n",
       "      <th>rank_x</th>\n",
       "      <th>count_y</th>\n",
       "      <th>rank_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B0088CJT4U</td>\n",
       "      <td>141.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B003ES5ZUU</td>\n",
       "      <td>130.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B000N99BBC</td>\n",
       "      <td>118.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B007WTAJTO</td>\n",
       "      <td>117.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B00829TIEK</td>\n",
       "      <td>105.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>B008DWCRQW</td>\n",
       "      <td>102.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>B00829THK0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>B002R5AM7C</td>\n",
       "      <td>90.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>B002SZEOLG</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>11.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>B00834SJNA</td>\n",
       "      <td>79.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    productId  count_x  rank_x  count_y  rank_y\n",
       "0  B0088CJT4U    141.0     1.0     65.0     1.0\n",
       "1  B003ES5ZUU    130.0     2.0     54.0     2.0\n",
       "2  B000N99BBC    118.0     3.0     49.0     3.0\n",
       "3  B007WTAJTO    117.0     4.0     47.0     4.0\n",
       "4  B00829TIEK    105.0     5.0     44.0     7.0\n",
       "5  B008DWCRQW    102.0     6.0     35.0    10.0\n",
       "6  B00829THK0     96.0     7.0     41.0     8.0\n",
       "7  B002R5AM7C     90.0     8.0     38.0     9.0\n",
       "8  B002SZEOLG     80.0     9.0     33.0    11.5\n",
       "9  B00834SJNA     79.0    10.0     31.0    15.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now let's merge both models & compare the ranks using RMSE\n",
    "recommend = recommend_train.merge(recommend_test, how='outer', left_on='productId', right_on='productId')\n",
    "\n",
    "#Let's check resultant DataFrame\n",
    "recommend.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "productId    48190\n",
       "count_x      38274\n",
       "rank_x       38274\n",
       "count_y      21287\n",
       "rank_y       21287\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's check NaN values\n",
    "recommend.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top N\tRMSE\n",
      "=====\t====\n",
      "1\t0.0\n",
      "2\t0.0\n",
      "3\t0.0\n",
      "4\t0.0\n",
      "5\t0.8944271909999159\n",
      "6\t1.8257418583505538\n",
      "7\t1.7320508075688772\n",
      "8\t1.6583123951777\n",
      "9\t1.7716909687891083\n",
      "10\t2.307596151842865\n",
      "11\t2.946492521934882\n",
      "12\t2.8540906315906183\n",
      "13\t4.1020632707118345\n",
      "14\t4.494043677071749\n",
      "15\t4.410215414239989\n",
      "16\t9.400797838481584\n",
      "17\t9.299746992130864\n",
      "18\t9.187098441715849\n",
      "19\t8.978043392515696\n",
      "20\t8.808376694942151\n",
      "21\t14.49794730954959\n",
      "22\t14.594908825901024\n",
      "23\t14.38371663888809\n",
      "24\t14.098980459593523\n",
      "25\t16.995293466133496\n",
      "26\t16.99547451076768\n",
      "27\t16.942440682980013\n",
      "28\t23.060866666900694\n",
      "29\t22.66148943578678\n",
      "30\t22.280596939938572\n",
      "31\t22.023997176100963\n",
      "32\t21.703074378990642\n",
      "33\t21.473556677076957\n",
      "34\t21.489224385860982\n",
      "35\t21.180179413782124\n",
      "36\t20.937738390019323\n",
      "37\t20.754843133917287\n",
      "38\t20.499358141427898\n",
      "39\t25.70518255637198\n",
      "40\t25.396727151347672\n",
      "41\t25.209246271179463\n",
      "42\t27.241425037894732\n",
      "43\t27.709875663783222\n",
      "44\t27.776400218367193\n",
      "45\t32.77778719397229\n",
      "46\t32.438403166617185\n",
      "47\t33.42170908702714\n",
      "48\t33.09448279799318\n",
      "49\t32.816045726791295\n",
      "50\t32.526911934581186\n",
      "51\t34.50838204512853\n",
      "52\t39.61655151380738\n",
      "53\t39.58666156150207\n",
      "54\t39.303543332866546\n",
      "55\t38.9530019849095\n",
      "56\t38.60387193755866\n",
      "57\t38.93871703344277\n",
      "58\t38.78894038964875\n",
      "59\t38.46079888467552\n",
      "60\t38.73650302578521\n",
      "61\t49.19532831345729\n",
      "62\t51.61695926602969\n",
      "63\t51.31439044426686\n",
      "64\t50.911956785709975\n",
      "65\t50.59245155006974\n",
      "66\t51.03831003186813\n",
      "67\t50.727248410920964\n",
      "68\t50.352908964393215\n",
      "69\t62.670549910519824\n",
      "70\t62.24886688584322\n",
      "71\t61.90141526061909\n",
      "72\t61.65506647650477\n",
      "73\t62.18104917667704\n",
      "74\t61.76341631252755\n",
      "75\t61.47948167207224\n",
      "76\t61.87442184737865\n",
      "77\t62.97409795294421\n",
      "78\t62.9617048852021\n",
      "79\t62.57651013162339\n",
      "80\t62.228485237871574\n",
      "81\t62.14437093982183\n",
      "82\t61.764896494889314\n",
      "83\t77.13798073769598\n",
      "84\t76.6779365422737\n",
      "85\t76.33985544531615\n",
      "86\t75.9526321175336\n",
      "87\t75.99434718844357\n",
      "88\t75.8315455167211\n",
      "89\t75.40618473725623\n",
      "90\t75.01572057464577\n",
      "91\t86.51914924924532\n",
      "92\t88.76368541146817\n",
      "93\t90.90632363823407\n",
      "94\t91.07388279665898\n",
      "95\t90.89395208877096\n",
      "96\t90.66987394756136\n",
      "97\t90.20820704656923\n",
      "98\t89.75365946720558\n",
      "99\t98.4323846273895\n",
      "100\t97.9489918273792\n"
     ]
    }
   ],
   "source": [
    "#Let's calculate RMSE for top N products for N up to 100\n",
    "print(\"Top N\\tRMSE\")\n",
    "print(\"=====\\t====\")\n",
    "for i in range(1, 101):\n",
    "    print(str(i) + '\\t' + str(((recommend['rank_x'].head(i) - recommend['rank_y'].head(i))**2).mean()**0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary:\n",
    "For **Popularity based Recommendation Model**, we can see that RMSE on unseen data is increasing gadually as we try recommending more & more Products. So, we can deploy this model to show top 5 or at best top 10 Products to Users who have not yet signed in but are browsing our Website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-based Model : Test Set\n",
      "RMSE: 1.0584\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.058358615314931"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's now evaluate Collaborative Model\n",
    "from surprise import Trainset, accuracy\n",
    "\n",
    "#Converting Pandas DataFrame into surprise Dataset\n",
    "data_test = Dataset.load_from_df(df_test[['userId', 'productId', 'ratings']], reader)\n",
    "\n",
    "#Since, we have already split data into train & test, we can use full testing data as testset\n",
    "data_test = data_test.build_full_trainset()\n",
    "\n",
    "#Above method gives us object of type Trainset which we need to convert to testset\n",
    "data_test = data_test.build_testset()\n",
    "\n",
    "#Predict with our trained Collaborative model based on trainset\n",
    "pred = algo.test(data_test)\n",
    "\n",
    "# get RMSE\n",
    "print(\"User-based Model : Test Set\")\n",
    "accuracy.rmse(pred, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary:\n",
    "Our trained Collaborative Model is giving an RMSE of approx 1 for the Test data which can be considered as good.\n",
    "\n",
    "Hence, we can consider this model to predict the likely rating which User would give to a new Product based on the ratings given by \"similar\" Users having similar habits.\n",
    "\n",
    "Then, we can recommend top N products which the User is likely to give good ratings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Get top - K ( K = 5) recommendations. Since our goal is to recommend new products to each user based on his/her habits, we will recommend 5 new products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.knns.KNNWithMeans at 0x1921fd3d0c8>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's retrain user-based Collaborative Model & then prepare a list of top 5 recommendations for each Users \n",
    "\n",
    "# Use user_based true/false to switch between user-based or item-based collaborative filtering\n",
    "algo = KNNWithMeans(k=50, sim_options={'name': 'cosine', 'user_based': True})\n",
    "\n",
    "#Converting Pandas DataFrame into surprise Dataset\n",
    "data = Dataset.load_from_df(df_subset[['userId', 'productId', 'ratings']], reader)\n",
    "\n",
    "#Since, we want to train the model on entire Dataset, we can use full (unsplit) Dataset\n",
    "data = data.build_full_trainset()\n",
    "\n",
    "#Training user-based Collaborative model\n",
    "algo.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Commenting out below set of code as trying to prepare entire Prediction matrix for unknown ratings is making the Laptop hang & isn't leading to result even after 2 to 3 hours\n",
    "\n",
    "#Now let's construct the Dataset of Users & Products which have no ratings\n",
    "#pivot_ratings = df_subset.pivot_table(values='ratings', index='userId', columns='productId').reset_index()\n",
    "\n",
    "#Let's break the pivot table again to obtain also the records in the Dataset for unknown ratings\n",
    "#unknown = pd.melt(pivot_ratings, value_name='ratings', id_vars = 'userId')\n",
    "\n",
    "#Keeping only the unknown values in the Dataset\n",
    "#unknown = unknown[unknown['ratings'].isna()]\n",
    "\n",
    "#Converting Pandas DataFrame into surprise Dataset\n",
    "#data_unknown = Dataset.load_from_df(unknown[['userId', 'productId', 'ratings']], reader)\n",
    "\n",
    "#Using full unknown data as testset\n",
    "#data_unknown = data_unknown.build_full_trainset()\n",
    "\n",
    "#Above method gives us object of type Trainset which we need to convert to testset\n",
    "#data_unknown = data_unknown.build_testset()\n",
    "\n",
    "#Predict with our trained Collaborative model based on trainset\n",
    "#pred_unknown = algo.test(data_unknown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import module daefaultdict from collections library\n",
    "from collections import defaultdict\n",
    "\n",
    "#Instead of above approach, we will define a function to predict top K (by default 5) Products for the given User ID\n",
    "def predict_top_K_ratings(user_id, K=5):\n",
    "    #Check if the user ID exists in the Dataset\n",
    "    if user_id in df_subset['userId'].unique():\n",
    "        #Filter the Dataset by given User ID\n",
    "        df_user = df_subset[df_subset['userId'] == user_id]\n",
    "        \n",
    "        #Get list of unknown Products for givevn User\n",
    "        list_unknown_prd = [i for i in df_subset['productId'].unique() if i not in df_user['productId'].unique()]\n",
    "        \n",
    "        #Convert the list into DataFrame\n",
    "        unknown = pd.DataFrame(list_unknown_prd)\n",
    "        \n",
    "        #Name the only column as productId\n",
    "        unknown.columns = ['productId']\n",
    "        \n",
    "        #Add column for userID with given User ID\n",
    "        unknown['userId'] = user_id\n",
    "        \n",
    "        #Add column for ratings with NaN\n",
    "        unknown['ratings'] = np.NaN\n",
    "        \n",
    "        #Converting Pandas DataFrame into surprise Dataset\n",
    "        data_unknown = Dataset.load_from_df(unknown[['userId', 'productId', 'ratings']], reader)\n",
    "\n",
    "        #Using full unknown data as testset\n",
    "        data_unknown = data_unknown.build_full_trainset()\n",
    "\n",
    "        #Above method gives us object of type Trainset which we need to convert to testset\n",
    "        data_unknown = data_unknown.build_testset()\n",
    "\n",
    "        #Predict with our trained Collaborative model based on trainset\n",
    "        pred_unknown = algo.test(data_unknown)\n",
    "        \n",
    "        #Initialize top_K list\n",
    "        top_K = defaultdict(list)\n",
    "        \n",
    "        #Iterate through predictions & store Product ID & corresponding predicted rating in top_K list\n",
    "        for uid, iid, true_r, est, _ in pred_unknown:\n",
    "            top_K[uid].append((iid, est))\n",
    "\n",
    "        #Then sort the predictions for each user and retrieve the K highest ones.\n",
    "        for uid, user_ratings in top_K.items():\n",
    "            user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "            top_K[uid] = user_ratings[:K]\n",
    "\n",
    "        #Converting it into DataFrame & printing out top K recommendations\n",
    "        top_K = pd.DataFrame(top_K)\n",
    "        print(\"Top\", K, \"recommendations for unknown Products for given User ID is as below:\")\n",
    "        print(top_K)\n",
    "\n",
    "    #If User not found\n",
    "    else:\n",
    "        print(\"User with ID\", user_id, \"not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 recommendations for unknown Products for given User ID is as below:\n",
      "     AT09WGFUM934H\n",
      "0  (0594451647, 5)\n",
      "1  (1400501520, 5)\n",
      "2  (1400501776, 5)\n",
      "3  (1400532620, 5)\n",
      "4  (787988002X, 5)\n"
     ]
    }
   ],
   "source": [
    "#Let's check the function with only user_id field\n",
    "predict_top_K_ratings(user_id='AT09WGFUM934H')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 15 recommendations for unknown Products for given User ID is as below:\n",
      "     A17HMM1M7T9PJ1\n",
      "0   (1400599997, 5)\n",
      "1   (1400698987, 5)\n",
      "2   (9984984362, 5)\n",
      "3   (B000001ON0, 5)\n",
      "4   (B00000J061, 5)\n",
      "5   (B00000J0GF, 5)\n",
      "6   (B00000J1U8, 5)\n",
      "7   (B00000J1V3, 5)\n",
      "8   (B00000J3NG, 5)\n",
      "9   (B00000J4DB, 5)\n",
      "10  (B00000J4DV, 5)\n",
      "11  (B00000J4EY, 5)\n",
      "12  (B00000JBLJ, 5)\n",
      "13  (B00000JBTM, 5)\n",
      "14  (B00000JD3O, 5)\n"
     ]
    }
   ],
   "source": [
    "#Let's check the function for another user_id & K=15\n",
    "predict_top_K_ratings(user_id='A17HMM1M7T9PJ1', K=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User with ID ABC not found.\n"
     ]
    }
   ],
   "source": [
    "#Let's check the function for unknown User\n",
    "predict_top_K_ratings(user_id='ABC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary:\n",
    "With our trained Collaborative Model, we could recommend top K products which the User is likely to give good ratings.\n",
    "\n",
    "Hence, we can deploy this Model to recommend top K products based on top ratings given by Users matching his/her past behaviour."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Summarise your insights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I have summarized my insights above after every question."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
